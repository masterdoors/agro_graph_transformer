{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bdca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2025-11-01 13:17:10,761]\u001b[0m A new study created in memory with name: no-name-956e75ff-85c1-4b6f-b5fe-6021eb1fb96c\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:17:26,191]\u001b[0m Trial 0 finished with value: 0.002902532521644662 and parameters: {'lr': 0.0068471765841184, 'hs': 27, 'dropout': 0.15527182418538327}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:17:29,500]\u001b[0m Trial 1 finished with value: 6.666666666666667e+25 and parameters: {'lr': 0.07212905336583822, 'hs': 28, 'dropout': 0.13597080037205714}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:17:35,154]\u001b[0m Trial 2 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.05840302182457777, 'hs': 28, 'dropout': 0.08960536373039948}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:17:50,214]\u001b[0m Trial 3 finished with value: 0.0035544852987771437 and parameters: {'lr': 0.003215809223014324, 'hs': 10, 'dropout': 0.17513206169368672}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:17:53,519]\u001b[0m Trial 4 finished with value: 6.666666666666667e+25 and parameters: {'lr': 0.08044689562586722, 'hs': 4, 'dropout': 0.05243062487772018}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:18:15,302]\u001b[0m Trial 5 finished with value: 0.003959288938375106 and parameters: {'lr': 0.0017907574502927788, 'hs': 28, 'dropout': 0.12866795025669925}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:18:21,396]\u001b[0m Trial 6 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.058758016995975014, 'hs': 5, 'dropout': 0.13384970914120603}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:18:28,163]\u001b[0m Trial 7 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.07655509603094424, 'hs': 17, 'dropout': 0.1633426776891217}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:18:31,917]\u001b[0m Trial 8 finished with value: 6.666666666666667e+25 and parameters: {'lr': 0.09434291802529056, 'hs': 25, 'dropout': 0.07093639008565211}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:18:40,405]\u001b[0m Trial 9 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.057439806941187374, 'hs': 29, 'dropout': 0.17162180936919189}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:18:55,711]\u001b[0m Trial 10 finished with value: 0.0029917315199498255 and parameters: {'lr': 0.028102132004052337, 'hs': 20, 'dropout': 0.19798088876472084}. Best is trial 0 with value: 0.002902532521644662.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:19:08,586]\u001b[0m Trial 11 finished with value: 0.0027217339184236835 and parameters: {'lr': 0.026705089855425017, 'hs': 20, 'dropout': 0.19974408878360086}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:19:18,906]\u001b[0m Trial 12 finished with value: 0.0028090273014460877 and parameters: {'lr': 0.025602780189633082, 'hs': 20, 'dropout': 0.194600953121942}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:19:29,422]\u001b[0m Trial 13 finished with value: 0.003005914293258863 and parameters: {'lr': 0.028398676630844152, 'hs': 18, 'dropout': 0.1999714633872962}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:19:40,626]\u001b[0m Trial 14 finished with value: 0.002968309904620166 and parameters: {'lr': 0.03275505720506785, 'hs': 13, 'dropout': 0.10225967162998335}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:19:51,080]\u001b[0m Trial 15 finished with value: 0.0031074785750172668 and parameters: {'lr': 0.03971038238288349, 'hs': 23, 'dropout': 0.18543287269595765}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:20:03,215]\u001b[0m Trial 16 finished with value: 0.0028792976123315777 and parameters: {'lr': 0.01627609631419944, 'hs': 32, 'dropout': 0.14653895068713704}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:20:13,788]\u001b[0m Trial 17 finished with value: 0.002898159717467425 and parameters: {'lr': 0.018037946177694497, 'hs': 14, 'dropout': 0.11076288995472534}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:20:22,185]\u001b[0m Trial 18 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.04485132048223599, 'hs': 22, 'dropout': 0.18341548733821839}. Best is trial 11 with value: 0.0027217339184236835.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:20:33,010]\u001b[0m Trial 19 finished with value: 0.002551316241844473 and parameters: {'lr': 0.019738815846411115, 'hs': 9, 'dropout': 0.18774299048310134}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:20:42,335]\u001b[0m Trial 20 finished with value: 0.003002549872716937 and parameters: {'lr': 0.015413673473053748, 'hs': 8, 'dropout': 0.15416481110090927}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:20:51,526]\u001b[0m Trial 21 finished with value: 0.0030114244880957105 and parameters: {'lr': 0.03736574195025179, 'hs': 14, 'dropout': 0.1875872457455507}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:21:01,853]\u001b[0m Trial 22 finished with value: 0.002956372655772067 and parameters: {'lr': 0.022486559214912123, 'hs': 20, 'dropout': 0.19512360299242418}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:21:14,782]\u001b[0m Trial 23 finished with value: 0.005139300744613607 and parameters: {'lr': 0.011712838405549235, 'hs': 2, 'dropout': 0.17247452749917264}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:21:24,205]\u001b[0m Trial 24 finished with value: 0.0031783510191075257 and parameters: {'lr': 0.04713499713027179, 'hs': 10, 'dropout': 0.17966193706763403}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:21:32,347]\u001b[0m Trial 25 finished with value: 0.0031376619473412666 and parameters: {'lr': 0.02406143962883434, 'hs': 19, 'dropout': 0.1646425148441141}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:21:44,306]\u001b[0m Trial 26 finished with value: 0.0029745601071951566 and parameters: {'lr': 0.03501723125915828, 'hs': 15, 'dropout': 0.19011520021145178}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:21:56,926]\u001b[0m Trial 27 finished with value: 0.0032617146762512635 and parameters: {'lr': 0.011377549462128458, 'hs': 24, 'dropout': 0.14570517792893478}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:22:07,222]\u001b[0m Trial 28 finished with value: 0.002964920768078163 and parameters: {'lr': 0.021846564982075815, 'hs': 16, 'dropout': 0.19958381271673264}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:22:21,309]\u001b[0m Trial 29 finished with value: 0.0029359977021346877 and parameters: {'lr': 0.009666334640366502, 'hs': 12, 'dropout': 0.16272084433969586}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:22:29,771]\u001b[0m Trial 30 finished with value: 0.0027638932874728974 and parameters: {'lr': 0.04304195190879927, 'hs': 21, 'dropout': 0.1523627257739883}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:22:41,741]\u001b[0m Trial 31 finished with value: 0.0030386548152015248 and parameters: {'lr': 0.04323832020623814, 'hs': 21, 'dropout': 0.18281162154060665}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:22:52,402]\u001b[0m Trial 32 finished with value: 0.0028250961093506514 and parameters: {'lr': 0.05318052294384979, 'hs': 25, 'dropout': 0.11487405517766698}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:23:03,294]\u001b[0m Trial 33 finished with value: 0.0028220894552750965 and parameters: {'lr': 0.03155833222850375, 'hs': 18, 'dropout': 0.14407793816955144}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:23:13,683]\u001b[0m Trial 34 finished with value: 0.002726592081581644 and parameters: {'lr': 0.05153147077263904, 'hs': 22, 'dropout': 0.155684370922397}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:23:20,674]\u001b[0m Trial 35 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.06668105432306365, 'hs': 26, 'dropout': 0.15461801810595904}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:23:29,297]\u001b[0m Trial 36 finished with value: 0.002752619108308492 and parameters: {'lr': 0.04973468089929165, 'hs': 22, 'dropout': 0.17051168429676358}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:23:36,561]\u001b[0m Trial 37 finished with value: 0.003772555552406128 and parameters: {'lr': 0.06668543509148728, 'hs': 7, 'dropout': 0.17412343101074934}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:23:40,279]\u001b[0m Trial 38 finished with value: 6.666666666666667e+25 and parameters: {'lr': 0.08390342605643197, 'hs': 23, 'dropout': 0.1706384557931334}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:23:48,040]\u001b[0m Trial 39 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.05125038022103663, 'hs': 30, 'dropout': 0.16277930932880402}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:23:54,360]\u001b[0m Trial 40 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.06373540025978024, 'hs': 27, 'dropout': 0.1225727726361803}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:24:05,160]\u001b[0m Trial 41 finished with value: 0.0027956987748580507 and parameters: {'lr': 0.05590391563596364, 'hs': 22, 'dropout': 0.13824347351522978}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:24:10,886]\u001b[0m Trial 42 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.0407675410647453, 'hs': 17, 'dropout': 0.15521309415335777}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:24:16,577]\u001b[0m Trial 43 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.050066464973819606, 'hs': 21, 'dropout': 0.18026108769980959}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:24:30,827]\u001b[0m Trial 44 finished with value: 0.0032211791227851777 and parameters: {'lr': 0.004135274645069702, 'hs': 24, 'dropout': 0.1672772413544473}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:24:39,183]\u001b[0m Trial 45 finished with value: 0.002799281204937519 and parameters: {'lr': 0.047407662391406404, 'hs': 19, 'dropout': 0.18904654743770383}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:24:50,029]\u001b[0m Trial 46 finished with value: 0.0027805055251750727 and parameters: {'lr': 0.05950684490367119, 'hs': 22, 'dropout': 0.12936282461789497}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "all elements of input should be between 0 and 1\n",
      "\u001b[32m[I 2025-11-01 13:24:58,358]\u001b[0m Trial 47 finished with value: 3.3333333333333335e+25 and parameters: {'lr': 0.0360687980328248, 'hs': 26, 'dropout': 0.1771234385367159}. Best is trial 19 with value: 0.002551316241844473.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:25:10,346]\u001b[0m Trial 48 finished with value: 0.0024986922996590648 and parameters: {'lr': 0.030472717780952337, 'hs': 16, 'dropout': 0.05198178950287051}. Best is trial 48 with value: 0.0024986922996590648.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:25:21,778]\u001b[0m Trial 49 finished with value: 0.0024958718825190697 and parameters: {'lr': 0.03091040834459444, 'hs': 12, 'dropout': 0.09579605653203363}. Best is trial 49 with value: 0.0024958718825190697.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:25:33,277]\u001b[0m Trial 50 finished with value: 0.0028468601650689755 and parameters: {'lr': 0.029245946094418163, 'hs': 11, 'dropout': 0.05048202772900319}. Best is trial 49 with value: 0.0024958718825190697.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:25:44,378]\u001b[0m Trial 51 finished with value: 0.0025104641227213426 and parameters: {'lr': 0.018558944016106985, 'hs': 8, 'dropout': 0.0631427862844844}. Best is trial 49 with value: 0.0024958718825190697.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:25:57,760]\u001b[0m Trial 52 finished with value: 0.0026924734218162043 and parameters: {'lr': 0.019603162366884377, 'hs': 7, 'dropout': 0.06373782741693043}. Best is trial 49 with value: 0.0024958718825190697.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:26:08,302]\u001b[0m Trial 53 finished with value: 0.0023280192720198756 and parameters: {'lr': 0.016796803895621923, 'hs': 8, 'dropout': 0.06253374338385245}. Best is trial 53 with value: 0.0023280192720198756.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:26:19,228]\u001b[0m Trial 54 finished with value: 0.0026579989960333673 and parameters: {'lr': 0.020238815879572734, 'hs': 8, 'dropout': 0.06293908983340898}. Best is trial 53 with value: 0.0023280192720198756.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:26:32,432]\u001b[0m Trial 55 finished with value: 0.003179837755635685 and parameters: {'lr': 0.006711565414922774, 'hs': 9, 'dropout': 0.0887153732808914}. Best is trial 53 with value: 0.0023280192720198756.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:26:45,881]\u001b[0m Trial 56 finished with value: 0.003666482680673279 and parameters: {'lr': 0.014574537955317421, 'hs': 4, 'dropout': 0.06401766192032396}. Best is trial 53 with value: 0.0023280192720198756.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:26:59,591]\u001b[0m Trial 57 finished with value: 0.0032900730105927794 and parameters: {'lr': 0.01882564447186405, 'hs': 6, 'dropout': 0.08241569439907437}. Best is trial 53 with value: 0.0023280192720198756.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:27:13,063]\u001b[0m Trial 58 finished with value: 0.002601814108223088 and parameters: {'lr': 0.02511542754349421, 'hs': 9, 'dropout': 0.05887194304804747}. Best is trial 53 with value: 0.0023280192720198756.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:27:23,875]\u001b[0m Trial 59 finished with value: 0.00225441433861844 and parameters: {'lr': 0.024690849892244668, 'hs': 11, 'dropout': 0.05749036591312548}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:27:34,742]\u001b[0m Trial 60 finished with value: 0.002729709416874488 and parameters: {'lr': 0.030385643654406415, 'hs': 12, 'dropout': 0.07121793267760913}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:27:46,830]\u001b[0m Trial 61 finished with value: 0.002988417084183907 and parameters: {'lr': 0.02692193742001093, 'hs': 10, 'dropout': 0.05950130872529161}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:27:57,259]\u001b[0m Trial 62 finished with value: 0.00262123265261386 and parameters: {'lr': 0.024955889410227184, 'hs': 9, 'dropout': 0.07644476716487153}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:28:09,275]\u001b[0m Trial 63 finished with value: 0.0028447377654884655 and parameters: {'lr': 0.013532088381016463, 'hs': 13, 'dropout': 0.05471086627240695}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:28:17,795]\u001b[0m Trial 64 finished with value: 0.003470286573902831 and parameters: {'lr': 0.03283703893614511, 'hs': 11, 'dropout': 0.07261560643070349}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:28:33,427]\u001b[0m Trial 65 finished with value: 0.0032473596506284023 and parameters: {'lr': 0.007969350522651294, 'hs': 4, 'dropout': 0.09643262510710061}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:28:43,589]\u001b[0m Trial 66 finished with value: 0.002566916944260441 and parameters: {'lr': 0.023049182756115786, 'hs': 9, 'dropout': 0.05832312189645536}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:28:53,270]\u001b[0m Trial 67 finished with value: 0.003002557729824411 and parameters: {'lr': 0.02104592007380958, 'hs': 6, 'dropout': 0.07878936259141621}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:29:34,416]\u001b[0m Trial 68 finished with value: 0.005223796269636274 and parameters: {'lr': 0.0005281639522836494, 'hs': 13, 'dropout': 0.06815630292133595}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:29:46,687]\u001b[0m Trial 69 finished with value: 0.0024471598060364767 and parameters: {'lr': 0.015303658600067153, 'hs': 11, 'dropout': 0.0540419550148781}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:29:59,278]\u001b[0m Trial 70 finished with value: 0.00274934357616546 and parameters: {'lr': 0.01715629946825066, 'hs': 15, 'dropout': 0.055207024887903106}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:30:09,932]\u001b[0m Trial 71 finished with value: 0.0029032198786052735 and parameters: {'lr': 0.013284684086505618, 'hs': 11, 'dropout': 0.05536387013088151}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:30:20,214]\u001b[0m Trial 72 finished with value: 0.0028548218045270136 and parameters: {'lr': 0.0228896735909329, 'hs': 8, 'dropout': 0.0678811180471001}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:30:37,463]\u001b[0m Trial 73 finished with value: 0.00282139614756903 and parameters: {'lr': 0.0051279369824669754, 'hs': 10, 'dropout': 0.051908158916587205}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:30:53,339]\u001b[0m Trial 74 finished with value: 0.0029961192357143792 and parameters: {'lr': 0.01065265413214674, 'hs': 12, 'dropout': 0.06052721078731085}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:31:03,248]\u001b[0m Trial 75 finished with value: 0.002889560036491529 and parameters: {'lr': 0.016743911042102926, 'hs': 7, 'dropout': 0.08811925184553279}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:31:17,305]\u001b[0m Trial 76 finished with value: 0.0028815657406199096 and parameters: {'lr': 0.028123665723332435, 'hs': 14, 'dropout': 0.067647080832722}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:31:26,676]\u001b[0m Trial 77 finished with value: 0.0036247259832467445 and parameters: {'lr': 0.03417732417118811, 'hs': 5, 'dropout': 0.10457508699558099}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:31:39,872]\u001b[0m Trial 78 finished with value: 0.002733003223414306 and parameters: {'lr': 0.021921091647648945, 'hs': 9, 'dropout': 0.07548361968281792}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:31:48,823]\u001b[0m Trial 79 finished with value: 0.0029551192872505736 and parameters: {'lr': 0.03894865362382059, 'hs': 8, 'dropout': 0.08380037185387705}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:32:00,723]\u001b[0m Trial 80 finished with value: 0.0025343154855883344 and parameters: {'lr': 0.01587155157685643, 'hs': 10, 'dropout': 0.05643204312519004}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:32:14,910]\u001b[0m Trial 81 finished with value: 0.002938720227442123 and parameters: {'lr': 0.008920848986257508, 'hs': 10, 'dropout': 0.059394987898229404}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:32:25,860]\u001b[0m Trial 82 finished with value: 0.002468448919661985 and parameters: {'lr': 0.0165108747998925, 'hs': 12, 'dropout': 0.055324511605136364}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:32:38,673]\u001b[0m Trial 83 finished with value: 0.0023158084615940667 and parameters: {'lr': 0.016130013592677225, 'hs': 11, 'dropout': 0.05342142611214424}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:32:50,054]\u001b[0m Trial 84 finished with value: 0.0026846346281589 and parameters: {'lr': 0.01570818505382233, 'hs': 13, 'dropout': 0.05396234963109715}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:33:03,336]\u001b[0m Trial 85 finished with value: 0.002519766797618264 and parameters: {'lr': 0.011539343787154842, 'hs': 15, 'dropout': 0.05038222337040479}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:33:15,464]\u001b[0m Trial 86 finished with value: 0.0022861596133780353 and parameters: {'lr': 0.013034580177360911, 'hs': 16, 'dropout': 0.050002279365572264}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:33:36,410]\u001b[0m Trial 87 finished with value: 0.002876233232329434 and parameters: {'lr': 0.0025195254600135983, 'hs': 16, 'dropout': 0.06441717707731977}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:33:48,341]\u001b[0m Trial 88 finished with value: 0.002671825258597712 and parameters: {'lr': 0.018678856957619918, 'hs': 16, 'dropout': 0.05056142776385223}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:34:00,775]\u001b[0m Trial 89 finished with value: 0.0023784907156105817 and parameters: {'lr': 0.013001843894264457, 'hs': 11, 'dropout': 0.06242586759211266}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:34:14,631]\u001b[0m Trial 90 finished with value: 0.0030968850092210885 and parameters: {'lr': 0.006901847805468975, 'hs': 12, 'dropout': 0.06703915488894052}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:34:27,451]\u001b[0m Trial 91 finished with value: 0.00257168608742327 and parameters: {'lr': 0.012803946935565002, 'hs': 14, 'dropout': 0.06278746816655079}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:34:39,888]\u001b[0m Trial 92 finished with value: 0.002984683049532809 and parameters: {'lr': 0.018040457300778273, 'hs': 11, 'dropout': 0.05623251832277292}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:34:51,134]\u001b[0m Trial 93 finished with value: 0.0025945488303132755 and parameters: {'lr': 0.025040194452344962, 'hs': 18, 'dropout': 0.0617474071705954}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:35:03,713]\u001b[0m Trial 94 finished with value: 0.0025905913238823118 and parameters: {'lr': 0.009667913247746487, 'hs': 13, 'dropout': 0.07184204609828262}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:35:15,714]\u001b[0m Trial 95 finished with value: 0.0029363296871884517 and parameters: {'lr': 0.026896312003751338, 'hs': 12, 'dropout': 0.06648537306516214}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:35:27,806]\u001b[0m Trial 96 finished with value: 0.0026848741307800516 and parameters: {'lr': 0.014227828424601692, 'hs': 11, 'dropout': 0.05411376626698796}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:35:41,094]\u001b[0m Trial 97 finished with value: 0.0026388166685472982 and parameters: {'lr': 0.03163493050139337, 'hs': 15, 'dropout': 0.058564611332666355}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:35:54,968]\u001b[0m Trial 98 finished with value: 0.002501888295411861 and parameters: {'lr': 0.011869398966260058, 'hs': 12, 'dropout': 0.05309218807282917}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:36:11,446]\u001b[0m Trial 99 finished with value: 0.0024678213196153258 and parameters: {'lr': 0.005322897794026632, 'hs': 14, 'dropout': 0.050278958353524264}. Best is trial 59 with value: 0.00225441433861844.\u001b[0m\n",
      "('TKAN', 1.3196156853703907e+17, 143699836.33571208, 4.602592076657459, 0.3031526665388876, 0.7794866597330243, 'FF', True, 'bce')\n",
      "('TKAN', 9.097829445937242e+16, 151787448.57061037, 12.644940323783397, 0.35244408833443863, 0.8495337003432977, 'FF', True, 'bce')\n",
      "('TKAN', 2.095232500315527e+17, 166886336.0943793, 6.992735357866713, 0.34429005034345467, 0.7131931332560114, 'FF', True, 'bce')\n",
      "('TKAN', 1.3554464927359862e+17, 148056133.64277413, 4.464776194795184, 0.31402209166470896, 0.8169440485613223, 'FF', True, 'bce')\n",
      "('TKAN', 1.6313447055278595e+17, 173499049.3670431, 8.974113051038886, 0.3695410368536224, 0.7923663906973057, 'FF', True, 'bce')\n",
      "\u001b[32m[I 2025-11-01 13:39:55,700]\u001b[0m A new study created in memory with name: no-name-28e3cd1a-1988-4c00-972d-1f899fd52e44\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:40:03,333]\u001b[0m Trial 0 finished with value: 2.2062730119642664 and parameters: {'lr': 0.039825208387876995, 'hs': 2, 'dropout': 0.07538681723914693}. Best is trial 0 with value: 2.2062730119642664.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:40:13,992]\u001b[0m Trial 1 finished with value: 2.2644859478257997 and parameters: {'lr': 0.01871132755937225, 'hs': 7, 'dropout': 0.102771374938119}. Best is trial 0 with value: 2.2062730119642664.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:41:00,362]\u001b[0m Trial 2 finished with value: 2.213927888433496 and parameters: {'lr': 0.05838427163060634, 'hs': 13, 'dropout': 0.09136791106649454}. Best is trial 0 with value: 2.2062730119642664.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:42:22,537]\u001b[0m Trial 3 finished with value: 4.361406510140771 and parameters: {'lr': 0.09203914006017198, 'hs': 5, 'dropout': 0.1476717678814244}. Best is trial 0 with value: 2.2062730119642664.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:43:48,703]\u001b[0m Trial 4 finished with value: 1.8161474456041298 and parameters: {'lr': 0.07444083430967612, 'hs': 20, 'dropout': 0.1125134225151653}. Best is trial 4 with value: 1.8161474456041298.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:43:59,211]\u001b[0m Trial 5 finished with value: 1.7924938754174857 and parameters: {'lr': 0.06376289558025801, 'hs': 22, 'dropout': 0.08373192684977981}. Best is trial 5 with value: 1.7924938754174857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:44:11,882]\u001b[0m Trial 6 finished with value: 1.8592763498217562 and parameters: {'lr': 0.05056641732223348, 'hs': 26, 'dropout': 0.159619211714601}. Best is trial 5 with value: 1.7924938754174857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:44:21,244]\u001b[0m Trial 7 finished with value: 1.7171376416785256 and parameters: {'lr': 0.05611731559182284, 'hs': 17, 'dropout': 0.17007236154471808}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:45:07,821]\u001b[0m Trial 8 finished with value: 3.947909510216155 and parameters: {'lr': 0.04200750177398386, 'hs': 9, 'dropout': 0.19583905223640835}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:45:19,487]\u001b[0m Trial 9 finished with value: 2.791235554319418 and parameters: {'lr': 0.007528868264417255, 'hs': 4, 'dropout': 0.1930717574865159}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:46:09,782]\u001b[0m Trial 10 finished with value: 1.9268729267881965 and parameters: {'lr': 0.09644888377646892, 'hs': 30, 'dropout': 0.05382122533531425}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:47:35,098]\u001b[0m Trial 11 finished with value: 2.386272778778597 and parameters: {'lr': 0.07052482994882364, 'hs': 20, 'dropout': 0.14435597095668673}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:47:43,200]\u001b[0m Trial 12 finished with value: 1.7525528491957847 and parameters: {'lr': 0.0704474451066109, 'hs': 15, 'dropout': 0.17021911346202492}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:47:53,109]\u001b[0m Trial 13 finished with value: 1.7732058647858018 and parameters: {'lr': 0.08096184871237741, 'hs': 14, 'dropout': 0.17120760993390505}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:48:01,637]\u001b[0m Trial 14 finished with value: 2.0643754627504958 and parameters: {'lr': 0.030315836885659787, 'hs': 14, 'dropout': 0.1763769301731942}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:48:49,757]\u001b[0m Trial 15 finished with value: 1.8003187489002885 and parameters: {'lr': 0.07962151807640323, 'hs': 17, 'dropout': 0.1392401809822889}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:48:57,762]\u001b[0m Trial 16 finished with value: 1.7427679006352783 and parameters: {'lr': 0.05556880459295497, 'hs': 11, 'dropout': 0.12424650176330425}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:49:43,130]\u001b[0m Trial 17 finished with value: 1.7812233272940485 and parameters: {'lr': 0.05357012468607365, 'hs': 11, 'dropout': 0.1279324192277986}. Best is trial 7 with value: 1.7171376416785256.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:49:52,356]\u001b[0m Trial 18 finished with value: 1.6982218084293184 and parameters: {'lr': 0.03231297065591378, 'hs': 25, 'dropout': 0.11609827392807218}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:50:04,061]\u001b[0m Trial 19 finished with value: 1.9692758490805844 and parameters: {'lr': 0.030426613357754467, 'hs': 26, 'dropout': 0.11587380526391218}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:50:20,562]\u001b[0m Trial 20 finished with value: 2.538237685489396 and parameters: {'lr': 0.004447328155978814, 'hs': 30, 'dropout': 0.15607083630119972}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:50:30,273]\u001b[0m Trial 21 finished with value: 1.8242937395826961 and parameters: {'lr': 0.04252115649230532, 'hs': 24, 'dropout': 0.1337174097395893}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:50:40,398]\u001b[0m Trial 22 finished with value: 1.7351639870278348 and parameters: {'lr': 0.028355686306522063, 'hs': 10, 'dropout': 0.11787825419901517}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:50:51,509]\u001b[0m Trial 23 finished with value: 1.9233998092638231 and parameters: {'lr': 0.02160476930899751, 'hs': 18, 'dropout': 0.10265177784276813}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:51:01,837]\u001b[0m Trial 24 finished with value: 1.864942777388956 and parameters: {'lr': 0.031033084284334208, 'hs': 27, 'dropout': 0.11052688865798113}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:51:14,044]\u001b[0m Trial 25 finished with value: 1.8163932980836428 and parameters: {'lr': 0.017996395093663596, 'hs': 32, 'dropout': 0.06797553960041397}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:51:25,944]\u001b[0m Trial 26 finished with value: 1.9143240387782015 and parameters: {'lr': 0.011348747739178211, 'hs': 17, 'dropout': 0.09488726810615125}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:51:35,941]\u001b[0m Trial 27 finished with value: 1.8781883725226975 and parameters: {'lr': 0.035492388912144554, 'hs': 22, 'dropout': 0.11995328498269253}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:51:46,693]\u001b[0m Trial 28 finished with value: 2.108501585236913 and parameters: {'lr': 0.024362944411100894, 'hs': 9, 'dropout': 0.15491344638603657}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:51:58,215]\u001b[0m Trial 29 finished with value: 1.722570571830034 and parameters: {'lr': 0.04517808414680991, 'hs': 20, 'dropout': 0.07439895072890709}. Best is trial 18 with value: 1.6982218084293184.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:52:07,485]\u001b[0m Trial 30 finished with value: 1.6208158071800511 and parameters: {'lr': 0.04496584806312198, 'hs': 23, 'dropout': 0.06650518026888956}. Best is trial 30 with value: 1.6208158071800511.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:52:17,090]\u001b[0m Trial 31 finished with value: 1.545928476642284 and parameters: {'lr': 0.04558384162665799, 'hs': 23, 'dropout': 0.06933932400845183}. Best is trial 31 with value: 1.545928476642284.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:52:27,544]\u001b[0m Trial 32 finished with value: 1.572354475075131 and parameters: {'lr': 0.06205196794781173, 'hs': 23, 'dropout': 0.06013755599255472}. Best is trial 31 with value: 1.545928476642284.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:52:36,026]\u001b[0m Trial 33 finished with value: 1.5118487633750972 and parameters: {'lr': 0.047673947236753174, 'hs': 24, 'dropout': 0.053614621240827734}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:53:27,924]\u001b[0m Trial 34 finished with value: 2.4288433209799147 and parameters: {'lr': 0.06217263343914231, 'hs': 23, 'dropout': 0.05481649448828942}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:53:40,265]\u001b[0m Trial 35 finished with value: 1.5393848603716596 and parameters: {'lr': 0.04679036306722131, 'hs': 29, 'dropout': 0.06415124790575033}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:53:51,645]\u001b[0m Trial 36 finished with value: 1.521520017881982 and parameters: {'lr': 0.06254133537996358, 'hs': 29, 'dropout': 0.06044850479017488}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:54:05,141]\u001b[0m Trial 37 finished with value: 1.5615133546960165 and parameters: {'lr': 0.0484455188776196, 'hs': 28, 'dropout': 0.0833552568478789}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:54:54,548]\u001b[0m Trial 38 finished with value: 3.1073661647201454 and parameters: {'lr': 0.04978170488993253, 'hs': 29, 'dropout': 0.07924279991823738}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:55:05,706]\u001b[0m Trial 39 finished with value: 1.543555964169436 and parameters: {'lr': 0.03855710562737975, 'hs': 32, 'dropout': 0.05026448933906738}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:55:17,684]\u001b[0m Trial 40 finished with value: 1.61336816902839 and parameters: {'lr': 0.03764246854904547, 'hs': 31, 'dropout': 0.060702414303934894}. Best is trial 33 with value: 1.5118487633750972.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:55:27,137]\u001b[0m Trial 41 finished with value: 1.4987208303617054 and parameters: {'lr': 0.03868426403909875, 'hs': 32, 'dropout': 0.07028362664267446}. Best is trial 41 with value: 1.4987208303617054.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:55:37,951]\u001b[0m Trial 42 finished with value: 1.523962152305285 and parameters: {'lr': 0.05866747121467985, 'hs': 32, 'dropout': 0.05295884634300603}. Best is trial 41 with value: 1.4987208303617054.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:56:35,121]\u001b[0m Trial 43 finished with value: 2.770616488399078 and parameters: {'lr': 0.05866759677017573, 'hs': 28, 'dropout': 0.06093604391937591}. Best is trial 41 with value: 1.4987208303617054.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:57:25,565]\u001b[0m Trial 44 finished with value: 3.257626479467348 and parameters: {'lr': 0.06938208488434698, 'hs': 30, 'dropout': 0.09093853447585856}. Best is trial 41 with value: 1.4987208303617054.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:57:34,408]\u001b[0m Trial 45 finished with value: 1.4887099956708731 and parameters: {'lr': 0.05248094367536342, 'hs': 32, 'dropout': 0.07423179797383433}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:58:27,025]\u001b[0m Trial 46 finished with value: 1.9085687611948405 and parameters: {'lr': 0.06555665184589908, 'hs': 32, 'dropout': 0.07428092214894108}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 13:59:20,722]\u001b[0m Trial 47 finished with value: 2.779932635897987 and parameters: {'lr': 0.05160597753337474, 'hs': 31, 'dropout': 0.0557455950819048}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:01:34,956]\u001b[0m Trial 48 finished with value: 4.317125479750422 and parameters: {'lr': 0.08280834914222107, 'hs': 27, 'dropout': 0.0819852732454663}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:01:44,294]\u001b[0m Trial 49 finished with value: 1.5774970232368766 and parameters: {'lr': 0.05946518455998537, 'hs': 29, 'dropout': 0.08932090697370973}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:03:16,111]\u001b[0m Trial 50 finished with value: 3.242937157615387 and parameters: {'lr': 0.07546308651335949, 'hs': 26, 'dropout': 0.06949153021555975}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:04:48,023]\u001b[0m Trial 51 finished with value: 3.004559637059798 and parameters: {'lr': 0.05593890100238972, 'hs': 29, 'dropout': 0.05037840391497698}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:05:37,233]\u001b[0m Trial 52 finished with value: 1.6127120595903783 and parameters: {'lr': 0.06707836071803144, 'hs': 31, 'dropout': 0.06504453616012046}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:05:44,954]\u001b[0m Trial 53 finished with value: 1.6632312045642763 and parameters: {'lr': 0.0525665142482054, 'hs': 28, 'dropout': 0.07640237707422773}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:05:59,303]\u001b[0m Trial 54 finished with value: 1.6212972309986462 and parameters: {'lr': 0.03981167962138424, 'hs': 30, 'dropout': 0.05945000713427937}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:06:11,429]\u001b[0m Trial 55 finished with value: 1.6082850517987601 and parameters: {'lr': 0.04824918120784031, 'hs': 32, 'dropout': 0.07145963873621752}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:06:24,728]\u001b[0m Trial 56 finished with value: 1.6285423704630204 and parameters: {'lr': 0.03473806622094152, 'hs': 25, 'dropout': 0.06370459684876416}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:07:13,654]\u001b[0m Trial 57 finished with value: 2.442983306815212 and parameters: {'lr': 0.05603473034986489, 'hs': 2, 'dropout': 0.05575540235466485}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:07:25,680]\u001b[0m Trial 58 finished with value: 1.617975279481821 and parameters: {'lr': 0.04330209909051088, 'hs': 27, 'dropout': 0.09590104468126363}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:08:18,663]\u001b[0m Trial 59 finished with value: 2.8591390776649397 and parameters: {'lr': 0.05871420095720994, 'hs': 31, 'dropout': 0.08501780582785734}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:09:13,364]\u001b[0m Trial 60 finished with value: 3.060085109523662 and parameters: {'lr': 0.07426496327153828, 'hs': 29, 'dropout': 0.050101051121041726}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:09:25,875]\u001b[0m Trial 61 finished with value: 1.6261375062434382 and parameters: {'lr': 0.03925170597891222, 'hs': 32, 'dropout': 0.05037725334534595}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:09:35,005]\u001b[0m Trial 62 finished with value: 1.5666947706603132 and parameters: {'lr': 0.04882126410915044, 'hs': 32, 'dropout': 0.05634015427009432}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:09:43,992]\u001b[0m Trial 63 finished with value: 1.6061874078223113 and parameters: {'lr': 0.0530325621433593, 'hs': 30, 'dropout': 0.06310968357164894}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:09:58,394]\u001b[0m Trial 64 finished with value: 1.7688320654222711 and parameters: {'lr': 0.03580694535189472, 'hs': 31, 'dropout': 0.07330059479043098}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:10:09,150]\u001b[0m Trial 65 finished with value: 1.7659831166521611 and parameters: {'lr': 0.026682280704665457, 'hs': 30, 'dropout': 0.06638641142980092}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:10:21,986]\u001b[0m Trial 66 finished with value: 1.7236146753791604 and parameters: {'lr': 0.040389239652427876, 'hs': 28, 'dropout': 0.058179979127500024}. Best is trial 45 with value: 1.4887099956708731.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:10:32,632]\u001b[0m Trial 67 finished with value: 1.4747876802249873 and parameters: {'lr': 0.04583938999488075, 'hs': 32, 'dropout': 0.053303893098895376}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:10:43,395]\u001b[0m Trial 68 finished with value: 1.7057204702953817 and parameters: {'lr': 0.061736934329187684, 'hs': 26, 'dropout': 0.07846442713825098}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:10:50,827]\u001b[0m Trial 69 finished with value: 1.5786767582277201 and parameters: {'lr': 0.04625837054161664, 'hs': 25, 'dropout': 0.07044610983945049}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:11:02,249]\u001b[0m Trial 70 finished with value: 1.5015457090443336 and parameters: {'lr': 0.05448779431385896, 'hs': 29, 'dropout': 0.06362314147774334}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:11:15,599]\u001b[0m Trial 71 finished with value: 1.5286086004280381 and parameters: {'lr': 0.054806668253604876, 'hs': 29, 'dropout': 0.06458842192514024}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:12:06,060]\u001b[0m Trial 72 finished with value: 1.8853602066106958 and parameters: {'lr': 0.055006752228001665, 'hs': 31, 'dropout': 0.05330146882412974}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:12:16,674]\u001b[0m Trial 73 finished with value: 1.5999238886778633 and parameters: {'lr': 0.06538019728475469, 'hs': 30, 'dropout': 0.06124673780530935}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:12:26,856]\u001b[0m Trial 74 finished with value: 1.4947815675763068 and parameters: {'lr': 0.05067264506277946, 'hs': 27, 'dropout': 0.06769747280548832}. Best is trial 67 with value: 1.4747876802249873.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:12:39,881]\u001b[0m Trial 75 finished with value: 1.4742840618398667 and parameters: {'lr': 0.04279810372149302, 'hs': 27, 'dropout': 0.057102267523900435}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:12:53,405]\u001b[0m Trial 76 finished with value: 1.6614886419566204 and parameters: {'lr': 0.0422326026868621, 'hs': 27, 'dropout': 0.08566987511413199}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:13:03,942]\u001b[0m Trial 77 finished with value: 1.6030620002498484 and parameters: {'lr': 0.04313243645493324, 'hs': 25, 'dropout': 0.07829775298002604}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:13:15,221]\u001b[0m Trial 78 finished with value: 1.6674834403399796 and parameters: {'lr': 0.050475866579233426, 'hs': 28, 'dropout': 0.10657976344207765}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:13:23,248]\u001b[0m Trial 79 finished with value: 1.7758486091292098 and parameters: {'lr': 0.050042911555234486, 'hs': 21, 'dropout': 0.1914456934210172}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:13:32,683]\u001b[0m Trial 80 finished with value: 1.6425625915816362 and parameters: {'lr': 0.03389002567134727, 'hs': 18, 'dropout': 0.06818076617213634}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:13:43,617]\u001b[0m Trial 81 finished with value: 1.4941475413068186 and parameters: {'lr': 0.060120223724634964, 'hs': 27, 'dropout': 0.05344355416857679}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:14:36,448]\u001b[0m Trial 82 finished with value: 1.620431086668619 and parameters: {'lr': 0.06152358756005589, 'hs': 26, 'dropout': 0.057135228883314335}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:14:47,983]\u001b[0m Trial 83 finished with value: 1.5729826234676276 and parameters: {'lr': 0.053059843803681145, 'hs': 27, 'dropout': 0.059414517368144494}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:15:00,911]\u001b[0m Trial 84 finished with value: 1.587463639918169 and parameters: {'lr': 0.04648423178719663, 'hs': 24, 'dropout': 0.07228999896481719}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:15:10,854]\u001b[0m Trial 85 finished with value: 1.5406456436069103 and parameters: {'lr': 0.05678150629430766, 'hs': 28, 'dropout': 0.06805281558912861}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:15:23,052]\u001b[0m Trial 86 finished with value: 1.5337141501873155 and parameters: {'lr': 0.0438883757932055, 'hs': 24, 'dropout': 0.05511357789756289}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:16:56,018]\u001b[0m Trial 87 finished with value: 3.3522122315842946 and parameters: {'lr': 0.06890645470492741, 'hs': 30, 'dropout': 0.06274240840249533}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:17:07,575]\u001b[0m Trial 88 finished with value: 1.5539490288224735 and parameters: {'lr': 0.03697059183306084, 'hs': 29, 'dropout': 0.05914079841447382}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:17:57,654]\u001b[0m Trial 89 finished with value: 2.50086729079555 and parameters: {'lr': 0.06409323004843143, 'hs': 31, 'dropout': 0.05354016713230845}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:18:07,517]\u001b[0m Trial 90 finished with value: 1.6534012256993151 and parameters: {'lr': 0.04090856922698989, 'hs': 26, 'dropout': 0.07550149779840498}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:19:01,168]\u001b[0m Trial 91 finished with value: 2.0723167264492037 and parameters: {'lr': 0.057329433972420664, 'hs': 32, 'dropout': 0.05262654828231778}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:19:53,487]\u001b[0m Trial 92 finished with value: 3.110742560733868 and parameters: {'lr': 0.059344558932061, 'hs': 31, 'dropout': 0.06620628879455588}. Best is trial 75 with value: 1.4742840618398667.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:20:02,265]\u001b[0m Trial 93 finished with value: 1.468023769370106 and parameters: {'lr': 0.0512227977736166, 'hs': 30, 'dropout': 0.05373584537006308}. Best is trial 93 with value: 1.468023769370106.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:20:12,483]\u001b[0m Trial 94 finished with value: 1.5187606729385326 and parameters: {'lr': 0.047701380687934024, 'hs': 27, 'dropout': 0.05880770626558886}. Best is trial 93 with value: 1.468023769370106.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:20:22,621]\u001b[0m Trial 95 finished with value: 1.5973034255620508 and parameters: {'lr': 0.04776498959547218, 'hs': 27, 'dropout': 0.056972629816899434}. Best is trial 93 with value: 1.468023769370106.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:20:33,966]\u001b[0m Trial 96 finished with value: 1.5329674795406865 and parameters: {'lr': 0.050220802089555136, 'hs': 28, 'dropout': 0.06339486298124881}. Best is trial 93 with value: 1.468023769370106.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:20:42,191]\u001b[0m Trial 97 finished with value: 1.6231496416507927 and parameters: {'lr': 0.05179531556886378, 'hs': 26, 'dropout': 0.08089863389058391}. Best is trial 93 with value: 1.468023769370106.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:20:53,301]\u001b[0m Trial 98 finished with value: 1.5833924468102942 and parameters: {'lr': 0.04571108743489257, 'hs': 24, 'dropout': 0.07018909331061952}. Best is trial 93 with value: 1.468023769370106.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:21:07,448]\u001b[0m Trial 99 finished with value: 1.451852736409671 and parameters: {'lr': 0.04811169277051059, 'hs': 30, 'dropout': 0.05215074131394432}. Best is trial 99 with value: 1.451852736409671.\u001b[0m\n",
      "('TKAN', 2.0509921749364416e+17, 150436073.98092932, 3.585006065821779, 0.32603548584913555, 0.7214476514140753, 'FF', True, 'mse')\n",
      "('TKAN', 1.802621341444594e+17, 162761410.62427068, 2.3786057067301303, 0.4052629101267208, 0.724493409430868, 'FF', True, 'mse')\n",
      "('TKAN', 1.9767568793003622e+17, 155557484.90433103, 2.174182115768312, 0.31350655190379084, 0.7033047660955678, 'FF', True, 'mse')\n",
      "('TKAN', 1.860418450207164e+17, 157206302.0892138, 2.7011036212444406, 0.3173456208311856, 0.7439973037673493, 'FF', True, 'mse')\n",
      "('TKAN', 1.2168098305926386e+17, 131425493.66541551, 1.8299008549189575, 0.3029973544674671, 0.8065497805649109, 'FF', True, 'mse')\n",
      "\u001b[32m[I 2025-11-01 14:25:13,917]\u001b[0m A new study created in memory with name: no-name-72940fa4-6937-4c68-a9de-b7cd25de780a\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:18,379]\u001b[0m Trial 0 finished with value: 0.0027157819264544366 and parameters: {'lr': 0.08677634942484443, 'hs': 10, 'dropout': 0.12188585928005298}. Best is trial 0 with value: 0.0027157819264544366.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:24,291]\u001b[0m Trial 1 finished with value: 0.0020949129872960986 and parameters: {'lr': 0.015994754031181176, 'hs': 26, 'dropout': 0.07096254540491881}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:30,019]\u001b[0m Trial 2 finished with value: 0.002496343674703766 and parameters: {'lr': 0.07102042986214899, 'hs': 22, 'dropout': 0.16207145294683112}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:34,726]\u001b[0m Trial 3 finished with value: 0.0025238607633332136 and parameters: {'lr': 0.054107577152582395, 'hs': 23, 'dropout': 0.09401521197943458}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:39,959]\u001b[0m Trial 4 finished with value: 0.0023262905117027496 and parameters: {'lr': 0.010985855520692017, 'hs': 27, 'dropout': 0.08760726864111179}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:44,433]\u001b[0m Trial 5 finished with value: 0.0024308311836314365 and parameters: {'lr': 0.04436386096129162, 'hs': 24, 'dropout': 0.14924436878414604}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:49,619]\u001b[0m Trial 6 finished with value: 0.002499253020540451 and parameters: {'lr': 0.012667956053282043, 'hs': 28, 'dropout': 0.17212794675638063}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:53,914]\u001b[0m Trial 7 finished with value: 0.0022758074702859256 and parameters: {'lr': 0.06521914687269748, 'hs': 19, 'dropout': 0.09938707906704428}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:25:57,369]\u001b[0m Trial 8 finished with value: 0.002689981181291196 and parameters: {'lr': 0.032321764843566234, 'hs': 16, 'dropout': 0.16164656352692497}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:00,553]\u001b[0m Trial 9 finished with value: 0.0032937991693962145 and parameters: {'lr': 0.08746886666919354, 'hs': 8, 'dropout': 0.15080259541582386}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:13,382]\u001b[0m Trial 10 finished with value: 0.002271753537133131 and parameters: {'lr': 0.0022293409329573206, 'hs': 31, 'dropout': 0.05045092474143899}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:28,676]\u001b[0m Trial 11 finished with value: 0.0028270881593556473 and parameters: {'lr': 0.0012365928707775958, 'hs': 31, 'dropout': 0.05380013110379387}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:33,594]\u001b[0m Trial 12 finished with value: 0.002329847949874672 and parameters: {'lr': 0.028545347650381584, 'hs': 32, 'dropout': 0.05167343374006454}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:37,875]\u001b[0m Trial 13 finished with value: 0.005751868481387483 and parameters: {'lr': 0.024294424840297278, 'hs': 3, 'dropout': 0.19994230329356974}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:45,031]\u001b[0m Trial 14 finished with value: 0.0021847308110821404 and parameters: {'lr': 0.004860902375972269, 'hs': 28, 'dropout': 0.07035607660885639}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:49,672]\u001b[0m Trial 15 finished with value: 0.0024176949648510256 and parameters: {'lr': 0.018561315480263456, 'hs': 15, 'dropout': 0.08105975934725052}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:26:56,596]\u001b[0m Trial 16 finished with value: 0.0024862229423493355 and parameters: {'lr': 0.03548954847846203, 'hs': 27, 'dropout': 0.07362987117292108}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:01,068]\u001b[0m Trial 17 finished with value: 0.0024496887909366024 and parameters: {'lr': 0.045284385167736155, 'hs': 21, 'dropout': 0.10415428108605648}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:07,007]\u001b[0m Trial 18 finished with value: 0.0022301197054496306 and parameters: {'lr': 0.009878912205263012, 'hs': 26, 'dropout': 0.06923498767587782}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:11,367]\u001b[0m Trial 19 finished with value: 0.002702912786888955 and parameters: {'lr': 0.016806626749776038, 'hs': 13, 'dropout': 0.1213335018989434}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:15,547]\u001b[0m Trial 20 finished with value: 0.002722234984298443 and parameters: {'lr': 0.09936436912320526, 'hs': 19, 'dropout': 0.06485939525621806}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:21,827]\u001b[0m Trial 21 finished with value: 0.002321249851935962 and parameters: {'lr': 0.007145681507536104, 'hs': 25, 'dropout': 0.07111602109793451}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:27,137]\u001b[0m Trial 22 finished with value: 0.0021350602433085047 and parameters: {'lr': 0.02162895092764011, 'hs': 29, 'dropout': 0.10425125014118039}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:32,197]\u001b[0m Trial 23 finished with value: 0.002411614841630602 and parameters: {'lr': 0.02232145050553653, 'hs': 29, 'dropout': 0.11055043042611391}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:37,590]\u001b[0m Trial 24 finished with value: 0.0022675946568263303 and parameters: {'lr': 0.035621507250144874, 'hs': 29, 'dropout': 0.08596604004839416}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:50,419]\u001b[0m Trial 25 finished with value: 0.0028470756043357122 and parameters: {'lr': 0.0015216085245618322, 'hs': 32, 'dropout': 0.1365789351288488}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:27:54,800]\u001b[0m Trial 26 finished with value: 0.002278111975605575 and parameters: {'lr': 0.02565518862585971, 'hs': 25, 'dropout': 0.10966231767484952}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:01,026]\u001b[0m Trial 27 finished with value: 0.0021935067647278 and parameters: {'lr': 0.016921827129698, 'hs': 20, 'dropout': 0.06240614878717031}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:06,822]\u001b[0m Trial 28 finished with value: 0.0022009074157322167 and parameters: {'lr': 0.04054690383129527, 'hs': 29, 'dropout': 0.08112655916235226}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:10,240]\u001b[0m Trial 29 finished with value: 0.002538422611527447 and parameters: {'lr': 0.0575890302292807, 'hs': 11, 'dropout': 0.1251691917000669}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:17,097]\u001b[0m Trial 30 finished with value: 0.002469466654020159 and parameters: {'lr': 0.006844621214418523, 'hs': 23, 'dropout': 0.11982776846751722}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:23,116]\u001b[0m Trial 31 finished with value: 0.002343996873479006 and parameters: {'lr': 0.015026050372100943, 'hs': 20, 'dropout': 0.0623051622221387}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:27,328]\u001b[0m Trial 32 finished with value: 0.0022601942947845705 and parameters: {'lr': 0.02077638029874762, 'hs': 18, 'dropout': 0.05983202280379004}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:32,460]\u001b[0m Trial 33 finished with value: 0.0023003866448730067 and parameters: {'lr': 0.029802584284140995, 'hs': 21, 'dropout': 0.09233148555082214}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:38,508]\u001b[0m Trial 34 finished with value: 0.002180480070794383 and parameters: {'lr': 0.015395191913896123, 'hs': 23, 'dropout': 0.07635517412662596}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:45,176]\u001b[0m Trial 35 finished with value: 0.002277691543824163 and parameters: {'lr': 0.007156629717886328, 'hs': 23, 'dropout': 0.07760775124908462}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:50,803]\u001b[0m Trial 36 finished with value: 0.002251094474437223 and parameters: {'lr': 0.012021067588347083, 'hs': 27, 'dropout': 0.09003556105189192}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:28:56,395]\u001b[0m Trial 37 finished with value: 0.002254206100096136 and parameters: {'lr': 0.07620143611977265, 'hs': 25, 'dropout': 0.0982736164931747}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:01,409]\u001b[0m Trial 38 finished with value: 0.002420936076649642 and parameters: {'lr': 0.049130998432933386, 'hs': 28, 'dropout': 0.08436417597746011}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:06,019]\u001b[0m Trial 39 finished with value: 0.00214406119176517 and parameters: {'lr': 0.03821335380259973, 'hs': 30, 'dropout': 0.07404153443251316}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:11,573]\u001b[0m Trial 40 finished with value: 0.002359195759891546 and parameters: {'lr': 0.03841883505413841, 'hs': 31, 'dropout': 0.10345045278011816}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:18,202]\u001b[0m Trial 41 finished with value: 0.0024586202094879156 and parameters: {'lr': 0.027055305805973172, 'hs': 30, 'dropout': 0.07476252166068512}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:24,519]\u001b[0m Trial 42 finished with value: 0.0022074581680065924 and parameters: {'lr': 0.02124920066717511, 'hs': 27, 'dropout': 0.09333785580599624}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:28,793]\u001b[0m Trial 43 finished with value: 0.002106749620533076 and parameters: {'lr': 0.055988641130785784, 'hs': 24, 'dropout': 0.05720031131979639}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:34,631]\u001b[0m Trial 44 finished with value: 0.0024879823460272543 and parameters: {'lr': 0.050003898575500284, 'hs': 24, 'dropout': 0.061321828610466166}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:38,983]\u001b[0m Trial 45 finished with value: 0.0022846255306456426 and parameters: {'lr': 0.056591653675985405, 'hs': 23, 'dropout': 0.05646390028533134}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:44,587]\u001b[0m Trial 46 finished with value: 0.002277071461848594 and parameters: {'lr': 0.07091661184454827, 'hs': 26, 'dropout': 0.050642894878743766}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:49,258]\u001b[0m Trial 47 finished with value: 0.0024655027544930657 and parameters: {'lr': 0.062229682263288226, 'hs': 30, 'dropout': 0.06838169257751882}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:53,605]\u001b[0m Trial 48 finished with value: 0.0022694369463566824 and parameters: {'lr': 0.043370683947683154, 'hs': 17, 'dropout': 0.08059009047920876}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:29:57,548]\u001b[0m Trial 49 finished with value: 0.0037572997276942785 and parameters: {'lr': 0.030058490915755787, 'hs': 6, 'dropout': 0.1881074243241006}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:00,926]\u001b[0m Trial 50 finished with value: 0.0024460614703867077 and parameters: {'lr': 0.03327427810143859, 'hs': 22, 'dropout': 0.13547413683384152}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:05,880]\u001b[0m Trial 51 finished with value: 0.002270342260352765 and parameters: {'lr': 0.011798767863175416, 'hs': 28, 'dropout': 0.0748976430882996}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:15,507]\u001b[0m Trial 52 finished with value: 0.0022474668830578747 and parameters: {'lr': 0.003996861442282227, 'hs': 26, 'dropout': 0.06960087041830362}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:21,024]\u001b[0m Trial 53 finished with value: 0.0022742450802863273 and parameters: {'lr': 0.0129417921259001, 'hs': 32, 'dropout': 0.05836392845037982}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:27,641]\u001b[0m Trial 54 finished with value: 0.002356330594706647 and parameters: {'lr': 0.018493124754496437, 'hs': 30, 'dropout': 0.08612333900662131}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:33,013]\u001b[0m Trial 55 finished with value: 0.002125647971199278 and parameters: {'lr': 0.05305272671315764, 'hs': 27, 'dropout': 0.06614272315908461}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:37,518]\u001b[0m Trial 56 finished with value: 0.0024101875608049236 and parameters: {'lr': 0.0638595301090452, 'hs': 24, 'dropout': 0.06651964337366724}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:43,248]\u001b[0m Trial 57 finished with value: 0.002317063054593361 and parameters: {'lr': 0.054760791337276786, 'hs': 26, 'dropout': 0.09830913952298523}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:48,471]\u001b[0m Trial 58 finished with value: 0.0022162303233925203 and parameters: {'lr': 0.059466503280633035, 'hs': 28, 'dropout': 0.054545421028795164}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:52,845]\u001b[0m Trial 59 finished with value: 0.002488483550670774 and parameters: {'lr': 0.04640132636078102, 'hs': 22, 'dropout': 0.07959352796084178}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:30:57,799]\u001b[0m Trial 60 finished with value: 0.0022595356772033663 and parameters: {'lr': 0.0712568170770072, 'hs': 24, 'dropout': 0.06574101527910324}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:03,063]\u001b[0m Trial 61 finished with value: 0.0021751886043109236 and parameters: {'lr': 0.05095523355065276, 'hs': 29, 'dropout': 0.07215947627648994}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:07,610]\u001b[0m Trial 62 finished with value: 0.0023580774508258798 and parameters: {'lr': 0.052402663587559656, 'hs': 29, 'dropout': 0.07402988664365347}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:13,189]\u001b[0m Trial 63 finished with value: 0.0021090413533352893 and parameters: {'lr': 0.06785336894084008, 'hs': 27, 'dropout': 0.05664853543509903}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:18,488]\u001b[0m Trial 64 finished with value: 0.0025644639629663225 and parameters: {'lr': 0.06741926214575071, 'hs': 31, 'dropout': 0.05618683392975806}. Best is trial 1 with value: 0.0020949129872960986.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:23,594]\u001b[0m Trial 65 finished with value: 0.002025144740944255 and parameters: {'lr': 0.08010063347737269, 'hs': 27, 'dropout': 0.06327485002375238}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:29,033]\u001b[0m Trial 66 finished with value: 0.0022891234158869908 and parameters: {'lr': 0.09135068682394765, 'hs': 27, 'dropout': 0.05238021452906758}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:33,525]\u001b[0m Trial 67 finished with value: 0.002313478390010712 and parameters: {'lr': 0.07876325202742172, 'hs': 25, 'dropout': 0.06329795598640275}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:38,576]\u001b[0m Trial 68 finished with value: 0.0024638995720979513 and parameters: {'lr': 0.0809953646247186, 'hs': 30, 'dropout': 0.059557667678940954}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:43,754]\u001b[0m Trial 69 finished with value: 0.002231902583930668 and parameters: {'lr': 0.09026205658197729, 'hs': 27, 'dropout': 0.11626877431932614}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:47,975]\u001b[0m Trial 70 finished with value: 0.002201578007237373 and parameters: {'lr': 0.06725023375741329, 'hs': 26, 'dropout': 0.05009220603924271}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:54,677]\u001b[0m Trial 71 finished with value: 0.0022216282240153395 and parameters: {'lr': 0.06094683417891302, 'hs': 29, 'dropout': 0.07018909794668683}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:31:59,652]\u001b[0m Trial 72 finished with value: 0.002240045189888769 and parameters: {'lr': 0.053308944901518836, 'hs': 28, 'dropout': 0.06582908704878102}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:04,720]\u001b[0m Trial 73 finished with value: 0.0021757492625116477 and parameters: {'lr': 0.0472515495514204, 'hs': 32, 'dropout': 0.08284232447690909}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:10,542]\u001b[0m Trial 74 finished with value: 0.0022933014104568484 and parameters: {'lr': 0.04259446779927353, 'hs': 29, 'dropout': 0.07051037346052276}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:14,432]\u001b[0m Trial 75 finished with value: 0.0027731271866005044 and parameters: {'lr': 0.08385149936145055, 'hs': 14, 'dropout': 0.08864051279548435}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:19,306]\u001b[0m Trial 76 finished with value: 0.0024765350343660245 and parameters: {'lr': 0.07439271744741782, 'hs': 31, 'dropout': 0.16285080437633595}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:25,202]\u001b[0m Trial 77 finished with value: 0.0022327250730512674 and parameters: {'lr': 0.03916650211169777, 'hs': 25, 'dropout': 0.05906128923727242}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:30,044]\u001b[0m Trial 78 finished with value: 0.002342508882065696 and parameters: {'lr': 0.05090011931902125, 'hs': 28, 'dropout': 0.1288077219370214}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:34,942]\u001b[0m Trial 79 finished with value: 0.0022817931725951676 and parameters: {'lr': 0.05559876836560202, 'hs': 30, 'dropout': 0.07730721319300189}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:39,510]\u001b[0m Trial 80 finished with value: 0.0022273376644225545 and parameters: {'lr': 0.03653689766871008, 'hs': 27, 'dropout': 0.07257896317948603}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:44,563]\u001b[0m Trial 81 finished with value: 0.0022879453999302673 and parameters: {'lr': 0.046988183454589404, 'hs': 31, 'dropout': 0.08532496743173755}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:50,155]\u001b[0m Trial 82 finished with value: 0.002123452523478854 and parameters: {'lr': 0.05766103940087673, 'hs': 32, 'dropout': 0.08289472828627141}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:32:55,185]\u001b[0m Trial 83 finished with value: 0.0022552363576988296 and parameters: {'lr': 0.05771942388458444, 'hs': 32, 'dropout': 0.06334293325374286}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:00,106]\u001b[0m Trial 84 finished with value: 0.0022988607195290572 and parameters: {'lr': 0.02310063027026206, 'hs': 29, 'dropout': 0.0552268506609127}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:05,158]\u001b[0m Trial 85 finished with value: 0.00226673957950674 and parameters: {'lr': 0.059170339835198274, 'hs': 26, 'dropout': 0.10388066502350989}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:10,171]\u001b[0m Trial 86 finished with value: 0.0022878837300620526 and parameters: {'lr': 0.06412149509993494, 'hs': 30, 'dropout': 0.11172070098177712}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:15,827]\u001b[0m Trial 87 finished with value: 0.002152367572743423 and parameters: {'lr': 0.06847477321446017, 'hs': 27, 'dropout': 0.06732068951774292}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:20,974]\u001b[0m Trial 88 finished with value: 0.002097397209490423 and parameters: {'lr': 0.06714961578019911, 'hs': 27, 'dropout': 0.0671783688070314}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:26,502]\u001b[0m Trial 89 finished with value: 0.002370126051589329 and parameters: {'lr': 0.07439417773679467, 'hs': 25, 'dropout': 0.061874507915632114}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:31,340]\u001b[0m Trial 90 finished with value: 0.002476179773625802 and parameters: {'lr': 0.06162836732425342, 'hs': 28, 'dropout': 0.09121397698234297}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:37,527]\u001b[0m Trial 91 finished with value: 0.0024367016856246516 and parameters: {'lr': 0.06740247927947489, 'hs': 26, 'dropout': 0.06707233577780115}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:42,041]\u001b[0m Trial 92 finished with value: 0.00239836084884138 and parameters: {'lr': 0.07270515985613513, 'hs': 27, 'dropout': 0.07819242100809101}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:47,513]\u001b[0m Trial 93 finished with value: 0.0030283206000889414 and parameters: {'lr': 0.06915270831857237, 'hs': 24, 'dropout': 0.05613793403641102}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:52,256]\u001b[0m Trial 94 finished with value: 0.002273437935765479 and parameters: {'lr': 0.06507735636092606, 'hs': 28, 'dropout': 0.0674483136445592}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:33:58,576]\u001b[0m Trial 95 finished with value: 0.002247163027223918 and parameters: {'lr': 0.07609810703828716, 'hs': 31, 'dropout': 0.05956245389099136}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:34:04,628]\u001b[0m Trial 96 finished with value: 0.0023050405001387914 and parameters: {'lr': 0.009557382162679734, 'hs': 26, 'dropout': 0.06410118781970034}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:34:08,920]\u001b[0m Trial 97 finished with value: 0.002618404946349686 and parameters: {'lr': 0.09792812147027619, 'hs': 11, 'dropout': 0.08212806071469318}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:34:14,839]\u001b[0m Trial 98 finished with value: 0.0021190324131559767 and parameters: {'lr': 0.0788283356681296, 'hs': 27, 'dropout': 0.09478268330636892}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:34:20,721]\u001b[0m Trial 99 finished with value: 0.002564727117682511 and parameters: {'lr': 0.08402166039750912, 'hs': 30, 'dropout': 0.07516056272501097}. Best is trial 65 with value: 0.002025144740944255.\u001b[0m\n",
      "('LSTM', 1.6857363840074717e+17, 161182949.26805395, 5.022105627657815, 0.34626723505035195, 0.7959686762145597, 'FF', True, 'bce')\n",
      "('LSTM', 2.035291283311614e+17, 172517226.0263927, 4.326116742877454, 0.3834437771412449, 0.7614778588132722, 'FF', True, 'bce')\n",
      "('LSTM', 8.901290283620245e+16, 127491777.74318253, 4.298161874810774, 0.2934632444478904, 0.8398421719615049, 'FF', True, 'bce')\n",
      "('LSTM', 1.3911119549295886e+17, 134633101.4824966, 8.244045138041763, 0.34096027407210844, 0.7802045609055187, 'FF', True, 'bce')\n",
      "('LSTM', 1.568149574488963e+17, 143731902.83811584, 6.779688832242433, 0.30193078662201445, 0.7857129867803145, 'FF', True, 'bce')\n",
      "\u001b[32m[I 2025-11-01 14:36:12,402]\u001b[0m A new study created in memory with name: no-name-8c7c5547-8841-4fe2-adcc-02ed708c9783\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:17,866]\u001b[0m Trial 0 finished with value: 1.9641004972887721 and parameters: {'lr': 0.03601749193003653, 'hs': 27, 'dropout': 0.12216335793915185}. Best is trial 0 with value: 1.9641004972887721.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:21,502]\u001b[0m Trial 1 finished with value: 1.9325647072760823 and parameters: {'lr': 0.05164592178912622, 'hs': 9, 'dropout': 0.06862369563966918}. Best is trial 1 with value: 1.9325647072760823.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:27,724]\u001b[0m Trial 2 finished with value: 2.126113650835442 and parameters: {'lr': 0.012879425094432857, 'hs': 24, 'dropout': 0.15811109470204082}. Best is trial 1 with value: 1.9325647072760823.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:31,464]\u001b[0m Trial 3 finished with value: 2.755951250408309 and parameters: {'lr': 0.03227875387364571, 'hs': 2, 'dropout': 0.15204248532107717}. Best is trial 1 with value: 1.9325647072760823.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:35,629]\u001b[0m Trial 4 finished with value: 2.4234456080649287 and parameters: {'lr': 0.017353009887255123, 'hs': 11, 'dropout': 0.19416992369107583}. Best is trial 1 with value: 1.9325647072760823.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:40,523]\u001b[0m Trial 5 finished with value: 2.351135400967637 and parameters: {'lr': 0.036600945514994335, 'hs': 3, 'dropout': 0.1840161938371767}. Best is trial 1 with value: 1.9325647072760823.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:44,850]\u001b[0m Trial 6 finished with value: 1.9166961669205065 and parameters: {'lr': 0.06800962107335966, 'hs': 19, 'dropout': 0.059943460051879054}. Best is trial 6 with value: 1.9166961669205065.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:48,528]\u001b[0m Trial 7 finished with value: 2.183053357547689 and parameters: {'lr': 0.07930192261115154, 'hs': 11, 'dropout': 0.1587981413827202}. Best is trial 6 with value: 1.9166961669205065.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:54,217]\u001b[0m Trial 8 finished with value: 2.509429070713912 and parameters: {'lr': 0.008251517592897873, 'hs': 13, 'dropout': 0.17961886054435566}. Best is trial 6 with value: 1.9166961669205065.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:36:58,986]\u001b[0m Trial 9 finished with value: 1.9509340397331458 and parameters: {'lr': 0.0673484641059238, 'hs': 27, 'dropout': 0.06288083219099033}. Best is trial 6 with value: 1.9166961669205065.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:04,770]\u001b[0m Trial 10 finished with value: 1.8535496480254838 and parameters: {'lr': 0.08630954746917308, 'hs': 20, 'dropout': 0.09522791311925521}. Best is trial 10 with value: 1.8535496480254838.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:08,531]\u001b[0m Trial 11 finished with value: 1.980626688623831 and parameters: {'lr': 0.0992645261670014, 'hs': 19, 'dropout': 0.09452496886002773}. Best is trial 10 with value: 1.8535496480254838.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:12,431]\u001b[0m Trial 12 finished with value: 1.9286530106287618 and parameters: {'lr': 0.0846070621326897, 'hs': 20, 'dropout': 0.09009330719528921}. Best is trial 10 with value: 1.8535496480254838.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:17,964]\u001b[0m Trial 13 finished with value: 1.773056999357422 and parameters: {'lr': 0.06070133172607614, 'hs': 32, 'dropout': 0.050488171433872325}. Best is trial 13 with value: 1.773056999357422.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:22,931]\u001b[0m Trial 14 finished with value: 1.8544276854537511 and parameters: {'lr': 0.09865103539758367, 'hs': 32, 'dropout': 0.0937827334591584}. Best is trial 13 with value: 1.773056999357422.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:28,015]\u001b[0m Trial 15 finished with value: 1.9164245408813054 and parameters: {'lr': 0.05715167743703772, 'hs': 32, 'dropout': 0.11834558451252689}. Best is trial 13 with value: 1.773056999357422.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:33,022]\u001b[0m Trial 16 finished with value: 1.7968020532190632 and parameters: {'lr': 0.08188223951234154, 'hs': 23, 'dropout': 0.08285824308055224}. Best is trial 13 with value: 1.773056999357422.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:38,422]\u001b[0m Trial 17 finished with value: 1.7559450530674183 and parameters: {'lr': 0.06746947328742552, 'hs': 25, 'dropout': 0.05058456216674966}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:42,922]\u001b[0m Trial 18 finished with value: 1.8757678340310864 and parameters: {'lr': 0.06528648110723646, 'hs': 28, 'dropout': 0.07479169742821896}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:48,333]\u001b[0m Trial 19 finished with value: 1.853296515698868 and parameters: {'lr': 0.04505080924547385, 'hs': 29, 'dropout': 0.05063171022573518}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:52,736]\u001b[0m Trial 20 finished with value: 1.9549800933234323 and parameters: {'lr': 0.05929057405779335, 'hs': 24, 'dropout': 0.10949248687222247}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:37:56,815]\u001b[0m Trial 21 finished with value: 1.9080515360593207 and parameters: {'lr': 0.07653376552277434, 'hs': 24, 'dropout': 0.05004975131947645}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:01,414]\u001b[0m Trial 22 finished with value: 1.8112742817879373 and parameters: {'lr': 0.07361059753058136, 'hs': 23, 'dropout': 0.07607848284990892}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:05,200]\u001b[0m Trial 23 finished with value: 2.0908574407415332 and parameters: {'lr': 0.08772906397011886, 'hs': 16, 'dropout': 0.08183833836386255}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:10,094]\u001b[0m Trial 24 finished with value: 1.8983982882608634 and parameters: {'lr': 0.047038894905149856, 'hs': 30, 'dropout': 0.061170972584748684}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:17,840]\u001b[0m Trial 25 finished with value: 1.7781351187456587 and parameters: {'lr': 0.05845169228670939, 'hs': 26, 'dropout': 0.13767345220858707}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:23,035]\u001b[0m Trial 26 finished with value: 2.1998694800835956 and parameters: {'lr': 0.05660715422884403, 'hs': 31, 'dropout': 0.14413948939701596}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:28,827]\u001b[0m Trial 27 finished with value: 2.0470736198164086 and parameters: {'lr': 0.04279427556087895, 'hs': 26, 'dropout': 0.13687478143470155}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:33,676]\u001b[0m Trial 28 finished with value: 1.9591031766659885 and parameters: {'lr': 0.025589881423987895, 'hs': 29, 'dropout': 0.10887241666193198}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:37,970]\u001b[0m Trial 29 finished with value: 1.9415117112942657 and parameters: {'lr': 0.06165069777910332, 'hs': 27, 'dropout': 0.1280676963164173}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:53,426]\u001b[0m Trial 30 finished with value: 3.968789411082326 and parameters: {'lr': 0.0004136797479742868, 'hs': 26, 'dropout': 0.16581740058739194}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:38:58,909]\u001b[0m Trial 31 finished with value: 2.0015428563695705 and parameters: {'lr': 0.07390700337957905, 'hs': 23, 'dropout': 0.08351980162600454}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:02,560]\u001b[0m Trial 32 finished with value: 1.95173549321592 and parameters: {'lr': 0.050945599749295106, 'hs': 22, 'dropout': 0.0687367187134031}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:06,292]\u001b[0m Trial 33 finished with value: 1.9223062755470686 and parameters: {'lr': 0.07054989839887243, 'hs': 17, 'dropout': 0.059566439357031084}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:12,255]\u001b[0m Trial 34 finished with value: 1.8353268172240373 and parameters: {'lr': 0.09134829805258399, 'hs': 25, 'dropout': 0.10504290840068436}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:16,999]\u001b[0m Trial 35 finished with value: 1.7601588433886455 and parameters: {'lr': 0.06208270906090095, 'hs': 22, 'dropout': 0.05060743963476819}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:21,934]\u001b[0m Trial 36 finished with value: 1.8417512579729036 and parameters: {'lr': 0.05399171879721916, 'hs': 21, 'dropout': 0.05128430385416341}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:26,339]\u001b[0m Trial 37 finished with value: 2.026041748356487 and parameters: {'lr': 0.061249372175995145, 'hs': 6, 'dropout': 0.13155217281535195}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:30,264]\u001b[0m Trial 38 finished with value: 1.9987209749352826 and parameters: {'lr': 0.040244019929219506, 'hs': 15, 'dropout': 0.0697200854282731}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:34,048]\u001b[0m Trial 39 finished with value: 2.0690662909540007 and parameters: {'lr': 0.027193497370362585, 'hs': 30, 'dropout': 0.11819122886790406}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:39,156]\u001b[0m Trial 40 finished with value: 1.9146801314492483 and parameters: {'lr': 0.05007642846835054, 'hs': 25, 'dropout': 0.14818552287642314}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:43,177]\u001b[0m Trial 41 finished with value: 1.9343006498495532 and parameters: {'lr': 0.07800458263639737, 'hs': 22, 'dropout': 0.057037323183556574}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:48,075]\u001b[0m Trial 42 finished with value: 1.929780967382075 and parameters: {'lr': 0.06596843250255159, 'hs': 28, 'dropout': 0.06674790093917646}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:52,056]\u001b[0m Trial 43 finished with value: 1.8844667560190451 and parameters: {'lr': 0.0710385261219102, 'hs': 18, 'dropout': 0.05595268884296489}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:39:58,068]\u001b[0m Trial 44 finished with value: 1.8422728627149327 and parameters: {'lr': 0.0804158631910934, 'hs': 21, 'dropout': 0.07715863537959038}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:03,815]\u001b[0m Trial 45 finished with value: 1.935724413587316 and parameters: {'lr': 0.06502261659929771, 'hs': 25, 'dropout': 0.08501052492267985}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:07,856]\u001b[0m Trial 46 finished with value: 1.983775004243111 and parameters: {'lr': 0.05559499003184867, 'hs': 14, 'dropout': 0.06521736305929283}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:12,639]\u001b[0m Trial 47 finished with value: 2.0774987626329606 and parameters: {'lr': 0.08301138341585125, 'hs': 19, 'dropout': 0.17043197384819894}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:17,530]\u001b[0m Trial 48 finished with value: 2.1033085831662834 and parameters: {'lr': 0.06257855201367349, 'hs': 27, 'dropout': 0.13776619469503856}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:22,768]\u001b[0m Trial 49 finished with value: 1.8897680190491624 and parameters: {'lr': 0.0903462093955808, 'hs': 23, 'dropout': 0.07270276850340854}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:27,799]\u001b[0m Trial 50 finished with value: 2.013736959619284 and parameters: {'lr': 0.06950118634298573, 'hs': 31, 'dropout': 0.19977576493587665}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:32,269]\u001b[0m Trial 51 finished with value: 1.874673152143363 and parameters: {'lr': 0.07359310117650608, 'hs': 23, 'dropout': 0.07977655785435309}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:36,952]\u001b[0m Trial 52 finished with value: 2.0314022849656883 and parameters: {'lr': 0.08165440002765473, 'hs': 20, 'dropout': 0.09986448838969544}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:42,239]\u001b[0m Trial 53 finished with value: 1.8927888355229652 and parameters: {'lr': 0.07537037928771118, 'hs': 22, 'dropout': 0.06269375188147823}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:46,835]\u001b[0m Trial 54 finished with value: 1.8440449638426915 and parameters: {'lr': 0.05831303604064553, 'hs': 24, 'dropout': 0.05447660460841241}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:52,082]\u001b[0m Trial 55 finished with value: 1.8145073883660672 and parameters: {'lr': 0.06753382808986166, 'hs': 26, 'dropout': 0.08800724327243417}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:40:56,680]\u001b[0m Trial 56 finished with value: 1.9268577919812495 and parameters: {'lr': 0.047005699243109156, 'hs': 29, 'dropout': 0.05008030919807331}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:00,671]\u001b[0m Trial 57 finished with value: 2.071801227601267 and parameters: {'lr': 0.09597551381900246, 'hs': 21, 'dropout': 0.1214032116555521}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:05,346]\u001b[0m Trial 58 finished with value: 1.9979793514775863 and parameters: {'lr': 0.06329117457412027, 'hs': 18, 'dropout': 0.0756614995558266}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:11,585]\u001b[0m Trial 59 finished with value: 1.8381529295644568 and parameters: {'lr': 0.05243933954096811, 'hs': 27, 'dropout': 0.05912855319445795}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:16,870]\u001b[0m Trial 60 finished with value: 1.7636481667721142 and parameters: {'lr': 0.07243556935843443, 'hs': 28, 'dropout': 0.07251616511858994}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:22,108]\u001b[0m Trial 61 finished with value: 1.8764911563142235 and parameters: {'lr': 0.07322791111991135, 'hs': 28, 'dropout': 0.07126775469073156}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:28,361]\u001b[0m Trial 62 finished with value: 1.8259924235200848 and parameters: {'lr': 0.05927659532055782, 'hs': 32, 'dropout': 0.09094104732009815}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:32,558]\u001b[0m Trial 63 finished with value: 1.9612320708055924 and parameters: {'lr': 0.07938193831805118, 'hs': 30, 'dropout': 0.06481697442649478}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:37,032]\u001b[0m Trial 64 finished with value: 1.8583591522369947 and parameters: {'lr': 0.06954875066997102, 'hs': 24, 'dropout': 0.0558293097743385}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:43,427]\u001b[0m Trial 65 finished with value: 1.898621045062545 and parameters: {'lr': 0.08435796693882469, 'hs': 26, 'dropout': 0.09771422274643182}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:47,786]\u001b[0m Trial 66 finished with value: 1.8930876835696957 and parameters: {'lr': 0.06636546643204215, 'hs': 28, 'dropout': 0.08012326841352582}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:52,803]\u001b[0m Trial 67 finished with value: 1.963736414683763 and parameters: {'lr': 0.08800639698921571, 'hs': 25, 'dropout': 0.06140049106890026}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:41:59,577]\u001b[0m Trial 68 finished with value: 1.8436720473942811 and parameters: {'lr': 0.07668521119322386, 'hs': 31, 'dropout': 0.06943824809873875}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:04,418]\u001b[0m Trial 69 finished with value: 1.8984767028329044 and parameters: {'lr': 0.07182689785617999, 'hs': 23, 'dropout': 0.05409418670367347}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:09,815]\u001b[0m Trial 70 finished with value: 1.8685998265030488 and parameters: {'lr': 0.05386473681497196, 'hs': 29, 'dropout': 0.11276313736545907}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:14,343]\u001b[0m Trial 71 finished with value: 1.904412605557857 and parameters: {'lr': 0.06791500585331167, 'hs': 26, 'dropout': 0.0860200281944134}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:19,809]\u001b[0m Trial 72 finished with value: 1.8182713981394532 and parameters: {'lr': 0.06099322957590533, 'hs': 26, 'dropout': 0.0881726025596216}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:24,909]\u001b[0m Trial 73 finished with value: 1.9329127841512046 and parameters: {'lr': 0.06406415153452706, 'hs': 24, 'dropout': 0.10354952820770733}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:28,756]\u001b[0m Trial 74 finished with value: 1.979770173535344 and parameters: {'lr': 0.0675209966352739, 'hs': 10, 'dropout': 0.07724109679717203}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:33,951]\u001b[0m Trial 75 finished with value: 2.043261439280703 and parameters: {'lr': 0.05593037921277157, 'hs': 27, 'dropout': 0.1377491697842557}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:40,565]\u001b[0m Trial 76 finished with value: 1.7791892692066993 and parameters: {'lr': 0.07834152803660385, 'hs': 25, 'dropout': 0.06649449939532245}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:44,548]\u001b[0m Trial 77 finished with value: 1.9846266728835005 and parameters: {'lr': 0.07746484096617251, 'hs': 22, 'dropout': 0.06534061360631385}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:50,070]\u001b[0m Trial 78 finished with value: 2.0376443428767668 and parameters: {'lr': 0.07415573823556844, 'hs': 25, 'dropout': 0.15652039375616547}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:53,012]\u001b[0m Trial 79 finished with value: 3.5787891889916494 and parameters: {'lr': 0.091704335923913, 'hs': 2, 'dropout': 0.07294449105056439}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:42:58,280]\u001b[0m Trial 80 finished with value: 1.9087017765517764 and parameters: {'lr': 0.059930394501399586, 'hs': 20, 'dropout': 0.05873586054514991}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:03,359]\u001b[0m Trial 81 finished with value: 1.9736305275074255 and parameters: {'lr': 0.07109006145469018, 'hs': 25, 'dropout': 0.14210969957959127}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:09,165]\u001b[0m Trial 82 finished with value: 1.9125124574112267 and parameters: {'lr': 0.07983619020006529, 'hs': 23, 'dropout': 0.08174037128791256}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:14,521]\u001b[0m Trial 83 finished with value: 1.9435025848611165 and parameters: {'lr': 0.06545632585889498, 'hs': 28, 'dropout': 0.06809481811354613}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:21,760]\u001b[0m Trial 84 finished with value: 1.7645043471761344 and parameters: {'lr': 0.08666985184090832, 'hs': 24, 'dropout': 0.05400494565040561}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:24,931]\u001b[0m Trial 85 finished with value: 2.1679893911062496 and parameters: {'lr': 0.0861550883268254, 'hs': 7, 'dropout': 0.053091992219355795}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:30,179]\u001b[0m Trial 86 finished with value: 2.072795292897992 and parameters: {'lr': 0.0887519635196925, 'hs': 24, 'dropout': 0.06275280514850952}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:35,145]\u001b[0m Trial 87 finished with value: 1.8705069464951016 and parameters: {'lr': 0.08396418501493261, 'hs': 21, 'dropout': 0.058210232352906885}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:40,823]\u001b[0m Trial 88 finished with value: 1.9101072420636136 and parameters: {'lr': 0.0931294322982228, 'hs': 27, 'dropout': 0.13154886040370573}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:45,497]\u001b[0m Trial 89 finished with value: 1.9148090097831412 and parameters: {'lr': 0.08150813699283402, 'hs': 22, 'dropout': 0.052492478524264544}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:43:52,175]\u001b[0m Trial 90 finished with value: 1.8200051920560918 and parameters: {'lr': 0.07556078091762063, 'hs': 29, 'dropout': 0.050555782093187375}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:00,244]\u001b[0m Trial 91 finished with value: 1.9180600399790837 and parameters: {'lr': 0.06825919934715845, 'hs': 26, 'dropout': 0.0737533571801641}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:07,132]\u001b[0m Trial 92 finished with value: 1.8601960906557042 and parameters: {'lr': 0.07213362491521533, 'hs': 23, 'dropout': 0.06152656689858367}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:12,964]\u001b[0m Trial 93 finished with value: 1.9790490918880792 and parameters: {'lr': 0.06285192895017523, 'hs': 24, 'dropout': 0.06636743311808274}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:17,163]\u001b[0m Trial 94 finished with value: 1.8740252989839046 and parameters: {'lr': 0.07811084811498213, 'hs': 26, 'dropout': 0.07707672776743049}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:22,054]\u001b[0m Trial 95 finished with value: 1.970862826673547 and parameters: {'lr': 0.06934448959399202, 'hs': 25, 'dropout': 0.09043243675889469}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:26,899]\u001b[0m Trial 96 finished with value: 1.874059198929371 and parameters: {'lr': 0.058080759502177955, 'hs': 22, 'dropout': 0.07000279503436736}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:32,724]\u001b[0m Trial 97 finished with value: 1.7900532851425013 and parameters: {'lr': 0.048114127168064805, 'hs': 30, 'dropout': 0.056574458783186565}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:38,529]\u001b[0m Trial 98 finished with value: 1.839780661544861 and parameters: {'lr': 0.041540562364411664, 'hs': 31, 'dropout': 0.05430564138289115}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:44:44,498]\u001b[0m Trial 99 finished with value: 1.870098452567274 and parameters: {'lr': 0.03518742016062753, 'hs': 30, 'dropout': 0.056697814750299697}. Best is trial 17 with value: 1.7559450530674183.\u001b[0m\n",
      "('LSTM', 2.1515699598048522e+17, 183217731.71552223, 1.1023952090465188, 0.42193774646394727, 0.6915202530887501, 'FF', True, 'mse')\n",
      "('LSTM', 1.9204102926903722e+17, 170824062.54537517, 1.4356418572684704, 0.42074522281724624, 0.6561183427828687, 'FF', True, 'mse')\n",
      "('LSTM', 1.1466320245022923e+17, 149540226.7588791, 2.92688778957412, 0.42260127360079836, 0.7651115682065207, 'FF', True, 'mse')\n",
      "('LSTM', 1.8390749239452355e+17, 166947363.3068613, 2.515877902108114, 0.37291770434211546, 0.7195039608661139, 'FF', True, 'mse')\n",
      "('LSTM', 2.6746585251661066e+17, 189205392.87540925, 3.001618727913435, 0.4174695254452142, 0.6985548681718237, 'FF', True, 'mse')\n",
      "\u001b[32m[I 2025-11-01 14:46:45,816]\u001b[0m A new study created in memory with name: no-name-f61e7743-34ca-4b21-8c34-86a43e02804a\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:46:50,359]\u001b[0m Trial 0 finished with value: 0.002677870071737003 and parameters: {'lr': 0.015135278277276053, 'hs': 10, 'dropout': 0.1213548658566353}. Best is trial 0 with value: 0.002677870071737003.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:46:55,947]\u001b[0m Trial 1 finished with value: 0.005285006855439051 and parameters: {'lr': 0.004213894265854289, 'hs': 5, 'dropout': 0.19116316683130202}. Best is trial 0 with value: 0.002677870071737003.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:00,118]\u001b[0m Trial 2 finished with value: 0.0032594476212285 and parameters: {'lr': 0.09773227953536609, 'hs': 3, 'dropout': 0.06613566208616162}. Best is trial 0 with value: 0.002677870071737003.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:05,228]\u001b[0m Trial 3 finished with value: 0.002704193624551774 and parameters: {'lr': 0.056954945575997264, 'hs': 28, 'dropout': 0.15061738482027448}. Best is trial 0 with value: 0.002677870071737003.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:09,602]\u001b[0m Trial 4 finished with value: 0.0032124777564182584 and parameters: {'lr': 0.022276887691732524, 'hs': 9, 'dropout': 0.16091421314870158}. Best is trial 0 with value: 0.002677870071737003.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:14,523]\u001b[0m Trial 5 finished with value: 0.0025480136307401997 and parameters: {'lr': 0.04479271709541236, 'hs': 19, 'dropout': 0.13493903882628522}. Best is trial 5 with value: 0.0025480136307401997.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:19,846]\u001b[0m Trial 6 finished with value: 0.0024529570875139735 and parameters: {'lr': 0.08459302168901692, 'hs': 31, 'dropout': 0.1008751135240353}. Best is trial 6 with value: 0.0024529570875139735.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:24,540]\u001b[0m Trial 7 finished with value: 0.002594436411346534 and parameters: {'lr': 0.08892312878360745, 'hs': 13, 'dropout': 0.055762956621900506}. Best is trial 6 with value: 0.0024529570875139735.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:28,158]\u001b[0m Trial 8 finished with value: 0.0033328269894475483 and parameters: {'lr': 0.06681910400731303, 'hs': 3, 'dropout': 0.11443647712308604}. Best is trial 6 with value: 0.0024529570875139735.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:31,737]\u001b[0m Trial 9 finished with value: 0.002806498223709606 and parameters: {'lr': 0.05129464035957433, 'hs': 9, 'dropout': 0.08553136975834313}. Best is trial 6 with value: 0.0024529570875139735.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:38,080]\u001b[0m Trial 10 finished with value: 0.0022774549981164857 and parameters: {'lr': 0.08060076991235676, 'hs': 31, 'dropout': 0.09597208407195801}. Best is trial 10 with value: 0.0022774549981164857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:43,472]\u001b[0m Trial 11 finished with value: 0.0023047248180398257 and parameters: {'lr': 0.08030281773787183, 'hs': 32, 'dropout': 0.09510233649353425}. Best is trial 10 with value: 0.0022774549981164857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:48,495]\u001b[0m Trial 12 finished with value: 0.002385271562933304 and parameters: {'lr': 0.07247016255618677, 'hs': 24, 'dropout': 0.0842578224073271}. Best is trial 10 with value: 0.0022774549981164857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:54,339]\u001b[0m Trial 13 finished with value: 0.002653983979911597 and parameters: {'lr': 0.0760466110460691, 'hs': 32, 'dropout': 0.09242718664398847}. Best is trial 10 with value: 0.0022774549981164857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:47:58,219]\u001b[0m Trial 14 finished with value: 0.002621655868982628 and parameters: {'lr': 0.09225248338882228, 'hs': 24, 'dropout': 0.06853302346370696}. Best is trial 10 with value: 0.0022774549981164857.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:02,753]\u001b[0m Trial 15 finished with value: 0.002214331529932215 and parameters: {'lr': 0.03488547394676543, 'hs': 27, 'dropout': 0.10450120282228255}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:06,886]\u001b[0m Trial 16 finished with value: 0.002804822735838443 and parameters: {'lr': 0.039863874186269625, 'hs': 25, 'dropout': 0.13526776174641558}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:11,824]\u001b[0m Trial 17 finished with value: 0.0025610541423298455 and parameters: {'lr': 0.03293047051599909, 'hs': 21, 'dropout': 0.11126793772356079}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:16,906]\u001b[0m Trial 18 finished with value: 0.002712704924153911 and parameters: {'lr': 0.06147822832680461, 'hs': 28, 'dropout': 0.15896306341867256}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:22,050]\u001b[0m Trial 19 finished with value: 0.0025359772107837997 and parameters: {'lr': 0.023377278052904134, 'hs': 17, 'dropout': 0.07332532776215257}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:27,881]\u001b[0m Trial 20 finished with value: 0.0027827029602561404 and parameters: {'lr': 0.03719628252074731, 'hs': 26, 'dropout': 0.19978803398491404}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:33,306]\u001b[0m Trial 21 finished with value: 0.0023428637314134543 and parameters: {'lr': 0.07899257653794764, 'hs': 30, 'dropout': 0.09851399504123967}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:38,069]\u001b[0m Trial 22 finished with value: 0.002696542996389547 and parameters: {'lr': 0.06760459814644956, 'hs': 32, 'dropout': 0.10692180297557125}. Best is trial 15 with value: 0.002214331529932215.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:42,625]\u001b[0m Trial 23 finished with value: 0.0022022203806398902 and parameters: {'lr': 0.09923304452640025, 'hs': 28, 'dropout': 0.1281981479318922}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:48,533]\u001b[0m Trial 24 finished with value: 0.0025365515848981687 and parameters: {'lr': 0.09896449298677781, 'hs': 28, 'dropout': 0.1321286390105713}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:52,605]\u001b[0m Trial 25 finished with value: 0.0027613712728839506 and parameters: {'lr': 0.09378574917608092, 'hs': 20, 'dropout': 0.14418164782034498}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:48:57,245]\u001b[0m Trial 26 finished with value: 0.0024440210822310737 and parameters: {'lr': 0.08643330501353923, 'hs': 22, 'dropout': 0.12161959844528294}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:06,736]\u001b[0m Trial 27 finished with value: 0.002494790457765321 and parameters: {'lr': 0.0030106520246818425, 'hs': 29, 'dropout': 0.17590434429067348}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:11,577]\u001b[0m Trial 28 finished with value: 0.002469096002311525 and parameters: {'lr': 0.053067647586069557, 'hs': 17, 'dropout': 0.08199599112848953}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:17,158]\u001b[0m Trial 29 finished with value: 0.002557934142443033 and parameters: {'lr': 0.029157612749166128, 'hs': 27, 'dropout': 0.12349569050207529}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:21,431]\u001b[0m Trial 30 finished with value: 0.002632354836528432 and parameters: {'lr': 0.012800255280414001, 'hs': 14, 'dropout': 0.11644018760688293}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:29,230]\u001b[0m Trial 31 finished with value: 0.0023766618790787945 and parameters: {'lr': 0.08134784966728216, 'hs': 30, 'dropout': 0.1015052580501626}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:34,504]\u001b[0m Trial 32 finished with value: 0.0022573755646768836 and parameters: {'lr': 0.07475320625405561, 'hs': 32, 'dropout': 0.09168033197519716}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:40,703]\u001b[0m Trial 33 finished with value: 0.002465180415985833 and parameters: {'lr': 0.07106916910093805, 'hs': 30, 'dropout': 0.057182172693775284}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:45,552]\u001b[0m Trial 34 finished with value: 0.0025876716742539363 and parameters: {'lr': 0.06239949595190134, 'hs': 23, 'dropout': 0.07934911546787876}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:52,124]\u001b[0m Trial 35 finished with value: 0.00250666602685992 and parameters: {'lr': 0.09419561620504942, 'hs': 26, 'dropout': 0.09067003775784996}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:49:57,786]\u001b[0m Trial 36 finished with value: 0.0028117671716884583 and parameters: {'lr': 0.04584302859052477, 'hs': 27, 'dropout': 0.10728007516248862}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:03,232]\u001b[0m Trial 37 finished with value: 0.002550271724079005 and parameters: {'lr': 0.01284131805113338, 'hs': 30, 'dropout': 0.13002724690280668}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:09,512]\u001b[0m Trial 38 finished with value: 0.002581700466662994 and parameters: {'lr': 0.058226919904529446, 'hs': 28, 'dropout': 0.1430144462651202}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:14,524]\u001b[0m Trial 39 finished with value: 0.00238469137189974 and parameters: {'lr': 0.09923933222251051, 'hs': 32, 'dropout': 0.07396496861223263}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:18,295]\u001b[0m Trial 40 finished with value: 0.002752080600062197 and parameters: {'lr': 0.08680304218424069, 'hs': 6, 'dropout': 0.06202919117825785}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:23,983]\u001b[0m Trial 41 finished with value: 0.0022497229515316165 and parameters: {'lr': 0.08095784632329311, 'hs': 32, 'dropout': 0.0945166714615238}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:29,044]\u001b[0m Trial 42 finished with value: 0.002359653741797391 and parameters: {'lr': 0.07550524699696874, 'hs': 29, 'dropout': 0.10564296974490499}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:35,219]\u001b[0m Trial 43 finished with value: 0.002449947808766402 and parameters: {'lr': 0.06615888328907057, 'hs': 31, 'dropout': 0.11619851613173586}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:40,328]\u001b[0m Trial 44 finished with value: 0.0026068153969467686 and parameters: {'lr': 0.09117941567442224, 'hs': 26, 'dropout': 0.09870707510262768}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:45,456]\u001b[0m Trial 45 finished with value: 0.002348652858679238 and parameters: {'lr': 0.08412270065042862, 'hs': 31, 'dropout': 0.09157252002467836}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:51,732]\u001b[0m Trial 46 finished with value: 0.002573032896247598 and parameters: {'lr': 0.045322720056362606, 'hs': 29, 'dropout': 0.08685627811829516}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:50:57,695]\u001b[0m Trial 47 finished with value: 0.002407520251666592 and parameters: {'lr': 0.07644488630880546, 'hs': 32, 'dropout': 0.07838698264454039}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:02,484]\u001b[0m Trial 48 finished with value: 0.0024847793330783838 and parameters: {'lr': 0.07227588633859858, 'hs': 25, 'dropout': 0.11166652653620912}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:07,337]\u001b[0m Trial 49 finished with value: 0.0025184168683792586 and parameters: {'lr': 0.08201122328994176, 'hs': 14, 'dropout': 0.10097930039451314}. Best is trial 23 with value: 0.0022022203806398902.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:11,792]\u001b[0m Trial 50 finished with value: 0.002049748870355269 and parameters: {'lr': 0.08841808770901674, 'hs': 31, 'dropout': 0.12515760143786672}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:16,186]\u001b[0m Trial 51 finished with value: 0.002163137489466587 and parameters: {'lr': 0.08973407983582037, 'hs': 31, 'dropout': 0.12913746569275683}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:21,827]\u001b[0m Trial 52 finished with value: 0.002356562842679606 and parameters: {'lr': 0.08945935403617267, 'hs': 29, 'dropout': 0.13909929769505933}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:26,662]\u001b[0m Trial 53 finished with value: 0.0024497980940282817 and parameters: {'lr': 0.09257605383789182, 'hs': 31, 'dropout': 0.15092942179762045}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:31,024]\u001b[0m Trial 54 finished with value: 0.00280913181972107 and parameters: {'lr': 0.0971307430877962, 'hs': 27, 'dropout': 0.12828173430577935}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:35,832]\u001b[0m Trial 55 finished with value: 0.0023979229033952655 and parameters: {'lr': 0.09606848532669894, 'hs': 30, 'dropout': 0.11953935355734821}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:40,059]\u001b[0m Trial 56 finished with value: 0.0025856922568008108 and parameters: {'lr': 0.087893916529396, 'hs': 32, 'dropout': 0.1257405793665886}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:45,083]\u001b[0m Trial 57 finished with value: 0.00231221046212389 and parameters: {'lr': 0.08466028676882233, 'hs': 28, 'dropout': 0.1514438374674241}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:50,097]\u001b[0m Trial 58 finished with value: 0.0025968807771689687 and parameters: {'lr': 0.018984183104342276, 'hs': 24, 'dropout': 0.13470468351899426}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:51:55,001]\u001b[0m Trial 59 finished with value: 0.002383476505760588 and parameters: {'lr': 0.0779565138844435, 'hs': 31, 'dropout': 0.11120021151124064}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:00,084]\u001b[0m Trial 60 finished with value: 0.002699788021896929 and parameters: {'lr': 0.03988280407928585, 'hs': 19, 'dropout': 0.1666310045511612}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:05,335]\u001b[0m Trial 61 finished with value: 0.0024825128681057545 and parameters: {'lr': 0.08149055468377608, 'hs': 31, 'dropout': 0.09639338114655892}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:10,581]\u001b[0m Trial 62 finished with value: 0.002359780333329457 and parameters: {'lr': 0.08853375215035017, 'hs': 29, 'dropout': 0.08885702755844246}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:18,166]\u001b[0m Trial 63 finished with value: 0.0026271849929030964 and parameters: {'lr': 0.029477612633109218, 'hs': 32, 'dropout': 0.12063518306037997}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:23,098]\u001b[0m Trial 64 finished with value: 0.0029668247733670382 and parameters: {'lr': 0.0699534466149817, 'hs': 11, 'dropout': 0.10452019625821755}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:27,761]\u001b[0m Trial 65 finished with value: 0.0025903704608111005 and parameters: {'lr': 0.09475318757557459, 'hs': 30, 'dropout': 0.14006235872570058}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:33,097]\u001b[0m Trial 66 finished with value: 0.0024168512998581186 and parameters: {'lr': 0.07490308452617392, 'hs': 27, 'dropout': 0.11398857611256186}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:40,199]\u001b[0m Trial 67 finished with value: 0.002512252074417574 and parameters: {'lr': 0.09034964760306742, 'hs': 28, 'dropout': 0.0948097063983271}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:48,117]\u001b[0m Trial 68 finished with value: 0.0025327735924692463 and parameters: {'lr': 0.09983428748464003, 'hs': 31, 'dropout': 0.12499456515596215}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:52,906]\u001b[0m Trial 69 finished with value: 0.0021332797961394006 and parameters: {'lr': 0.07907704781037024, 'hs': 25, 'dropout': 0.0694471939995877}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:52:57,184]\u001b[0m Trial 70 finished with value: 0.002227278696030524 and parameters: {'lr': 0.08382788410276998, 'hs': 25, 'dropout': 0.060033441985766496}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:01,763]\u001b[0m Trial 71 finished with value: 0.002424076794703737 and parameters: {'lr': 0.08392533543738863, 'hs': 25, 'dropout': 0.0665491539452239}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:06,494]\u001b[0m Trial 72 finished with value: 0.0023729777701135333 and parameters: {'lr': 0.08035667687082587, 'hs': 23, 'dropout': 0.06062616828143525}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:10,913]\u001b[0m Trial 73 finished with value: 0.0024976311512378262 and parameters: {'lr': 0.08650715467182818, 'hs': 26, 'dropout': 0.07365657197120774}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:16,576]\u001b[0m Trial 74 finished with value: 0.0022670213623898123 and parameters: {'lr': 0.0913744062120337, 'hs': 28, 'dropout': 0.06217056161067831}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:21,903]\u001b[0m Trial 75 finished with value: 0.0025958867930173973 and parameters: {'lr': 0.09553864836974492, 'hs': 22, 'dropout': 0.05462162204826266}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:25,713]\u001b[0m Trial 76 finished with value: 0.003321616654116875 and parameters: {'lr': 0.0648880913953968, 'hs': 2, 'dropout': 0.08303834707831409}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:35,134]\u001b[0m Trial 77 finished with value: 0.0023855665925843514 and parameters: {'lr': 0.07420058480312726, 'hs': 29, 'dropout': 0.07036487060402435}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:38,824]\u001b[0m Trial 78 finished with value: 0.002728266076575822 and parameters: {'lr': 0.049654473453159736, 'hs': 24, 'dropout': 0.07822393860115302}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:43,576]\u001b[0m Trial 79 finished with value: 0.0024503305617688243 and parameters: {'lr': 0.0776830520243289, 'hs': 25, 'dropout': 0.13072276911070493}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:49,446]\u001b[0m Trial 80 finished with value: 0.002471849540858567 and parameters: {'lr': 0.06913471043491497, 'hs': 27, 'dropout': 0.13629866025122164}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:55,340]\u001b[0m Trial 81 finished with value: 0.0023409010207824533 and parameters: {'lr': 0.09249929258274897, 'hs': 30, 'dropout': 0.059561320867792075}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:53:59,926]\u001b[0m Trial 82 finished with value: 0.002509322742572559 and parameters: {'lr': 0.08436251500228958, 'hs': 28, 'dropout': 0.06504370533806153}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:07,258]\u001b[0m Trial 83 finished with value: 0.0023554463050036614 and parameters: {'lr': 0.008188506607486611, 'hs': 32, 'dropout': 0.05120611894430492}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:10,841]\u001b[0m Trial 84 finished with value: 0.002593570225218203 and parameters: {'lr': 0.09179097629668892, 'hs': 26, 'dropout': 0.0682267716724543}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:15,248]\u001b[0m Trial 85 finished with value: 0.0023011220711407036 and parameters: {'lr': 0.09712182886173852, 'hs': 29, 'dropout': 0.0515189071120887}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:19,699]\u001b[0m Trial 86 finished with value: 0.0023881053477242706 and parameters: {'lr': 0.08954730583698206, 'hs': 28, 'dropout': 0.06386517779095656}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:24,291]\u001b[0m Trial 87 finished with value: 0.0021689238897832316 and parameters: {'lr': 0.08216264369206311, 'hs': 30, 'dropout': 0.07123714767968276}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:29,073]\u001b[0m Trial 88 finished with value: 0.0022609668220774817 and parameters: {'lr': 0.08281024740139889, 'hs': 30, 'dropout': 0.07085570400750295}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:34,419]\u001b[0m Trial 89 finished with value: 0.0024735286584945284 and parameters: {'lr': 0.08588965624895244, 'hs': 31, 'dropout': 0.14537741702577164}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:40,538]\u001b[0m Trial 90 finished with value: 0.0022753032836257607 and parameters: {'lr': 0.079190698181746, 'hs': 23, 'dropout': 0.08702110207368673}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:45,160]\u001b[0m Trial 91 finished with value: 0.002538439950129942 and parameters: {'lr': 0.0833997005571401, 'hs': 30, 'dropout': 0.07137721694947083}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:50,549]\u001b[0m Trial 92 finished with value: 0.0023835563735221436 and parameters: {'lr': 0.07383470518055145, 'hs': 32, 'dropout': 0.07650258122361185}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:54:55,865]\u001b[0m Trial 93 finished with value: 0.0026681756614312575 and parameters: {'lr': 0.08186529673138254, 'hs': 30, 'dropout': 0.08121575650836238}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:55:01,546]\u001b[0m Trial 94 finished with value: 0.002240403936606296 and parameters: {'lr': 0.07899989824200725, 'hs': 29, 'dropout': 0.11720292865341675}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:55:07,650]\u001b[0m Trial 95 finished with value: 0.0022100215926122665 and parameters: {'lr': 0.056988505864270976, 'hs': 27, 'dropout': 0.10908254530847952}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:55:13,404]\u001b[0m Trial 96 finished with value: 0.002560198300012271 and parameters: {'lr': 0.03365074453607722, 'hs': 27, 'dropout': 0.11889485803790299}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:55:18,086]\u001b[0m Trial 97 finished with value: 0.0023953123574698247 and parameters: {'lr': 0.05483691251555613, 'hs': 26, 'dropout': 0.10855483855568487}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:55:22,694]\u001b[0m Trial 98 finished with value: 0.002911779786793288 and parameters: {'lr': 0.06014374697292356, 'hs': 16, 'dropout': 0.1174301170201275}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:55:27,646]\u001b[0m Trial 99 finished with value: 0.0024543521267827943 and parameters: {'lr': 0.02321482810807937, 'hs': 25, 'dropout': 0.12690553451347875}. Best is trial 50 with value: 0.002049748870355269.\u001b[0m\n",
      "('GRU', 1.1462255609815856e+17, 150178924.40982777, 15.68202113524906, 0.3193907736806826, 0.8097009596613405, 'FF', True, 'bce')\n",
      "('GRU', 9.698974912693922e+16, 139032327.70414707, 4.273005498933227, 0.3128145765892668, 0.8201221946570308, 'FF', True, 'bce')\n",
      "('GRU', 1.527919026011143e+17, 136677241.32595944, 7.788693273905224, 0.35082506413507364, 0.7282810661520891, 'FF', True, 'bce')\n",
      "('GRU', 1.9625902801269386e+17, 169144863.05598038, 6.368905740894644, 0.3512474072175421, 0.7489510636513949, 'FF', True, 'bce')\n",
      "('GRU', 1.3761981720270336e+17, 142288246.6288739, 6.999577636424859, 0.3055994417267476, 0.8019428105498212, 'FF', True, 'bce')\n",
      "\u001b[32m[I 2025-11-01 14:57:28,362]\u001b[0m A new study created in memory with name: no-name-a444b4f3-8358-46f0-928e-560ad8256f00\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:32,443]\u001b[0m Trial 0 finished with value: 2.0287422808979616 and parameters: {'lr': 0.023284894406033454, 'hs': 16, 'dropout': 0.07072745925481293}. Best is trial 0 with value: 2.0287422808979616.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:36,177]\u001b[0m Trial 1 finished with value: 1.8511471287714 and parameters: {'lr': 0.06305449077796799, 'hs': 18, 'dropout': 0.1352765417070586}. Best is trial 1 with value: 1.8511471287714.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:41,052]\u001b[0m Trial 2 finished with value: 1.7675440250562577 and parameters: {'lr': 0.07259305126040588, 'hs': 19, 'dropout': 0.10736007931698134}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:46,258]\u001b[0m Trial 3 finished with value: 2.4841547350396254 and parameters: {'lr': 0.0068903928025782915, 'hs': 23, 'dropout': 0.19290543271641036}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:50,315]\u001b[0m Trial 4 finished with value: 1.8696786928786597 and parameters: {'lr': 0.03263992439837608, 'hs': 20, 'dropout': 0.05171822409570151}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:54,855]\u001b[0m Trial 5 finished with value: 1.7805242148717946 and parameters: {'lr': 0.08446868801127069, 'hs': 25, 'dropout': 0.06408545047432021}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:57:58,693]\u001b[0m Trial 6 finished with value: 1.8311485114326593 and parameters: {'lr': 0.09993753290454688, 'hs': 28, 'dropout': 0.12059984633980873}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:03,438]\u001b[0m Trial 7 finished with value: 1.7677440696005329 and parameters: {'lr': 0.0616442486830158, 'hs': 32, 'dropout': 0.15708885796656805}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:07,307]\u001b[0m Trial 8 finished with value: 1.799215889734321 and parameters: {'lr': 0.051653034459210954, 'hs': 11, 'dropout': 0.05199116652887025}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:12,999]\u001b[0m Trial 9 finished with value: 1.793045302836526 and parameters: {'lr': 0.09551375301741034, 'hs': 32, 'dropout': 0.07544875086433893}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:16,249]\u001b[0m Trial 10 finished with value: 2.36168733868182 and parameters: {'lr': 0.07800881229435126, 'hs': 3, 'dropout': 0.10178046578025918}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:20,197]\u001b[0m Trial 11 finished with value: 1.9730241388723433 and parameters: {'lr': 0.06606522238753883, 'hs': 10, 'dropout': 0.1626935330371435}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:25,079]\u001b[0m Trial 12 finished with value: 1.8111395643213706 and parameters: {'lr': 0.04466415445052237, 'hs': 31, 'dropout': 0.1592428178447441}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:29,757]\u001b[0m Trial 13 finished with value: 1.8387116898095777 and parameters: {'lr': 0.062270483733163046, 'hs': 13, 'dropout': 0.09934145859114739}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:32,514]\u001b[0m Trial 14 finished with value: 2.458101342584626 and parameters: {'lr': 0.08222614356815638, 'hs': 4, 'dropout': 0.15182486873014936}. Best is trial 2 with value: 1.7675440250562577.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:38,315]\u001b[0m Trial 15 finished with value: 1.7307043584556705 and parameters: {'lr': 0.046036951445522806, 'hs': 25, 'dropout': 0.19328045063875707}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:43,660]\u001b[0m Trial 16 finished with value: 1.9520237212820952 and parameters: {'lr': 0.03932250741847336, 'hs': 23, 'dropout': 0.1994018336347093}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:48,989]\u001b[0m Trial 17 finished with value: 2.0658834124155816 and parameters: {'lr': 0.021068163128315644, 'hs': 27, 'dropout': 0.17923639656249432}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:52,927]\u001b[0m Trial 18 finished with value: 1.799472847814066 and parameters: {'lr': 0.054545362000463775, 'hs': 20, 'dropout': 0.09946985481930884}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:58:57,654]\u001b[0m Trial 19 finished with value: 1.7379858882472128 and parameters: {'lr': 0.07340467289207867, 'hs': 15, 'dropout': 0.11953487271321857}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:02,998]\u001b[0m Trial 20 finished with value: 4.513144016915497 and parameters: {'lr': 0.0019777560488208265, 'hs': 8, 'dropout': 0.1346845134040229}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:07,085]\u001b[0m Trial 21 finished with value: 1.7794461376578947 and parameters: {'lr': 0.06923565298944345, 'hs': 16, 'dropout': 0.11560151750705869}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:10,946]\u001b[0m Trial 22 finished with value: 1.8713689749161897 and parameters: {'lr': 0.07522657964829194, 'hs': 14, 'dropout': 0.08422489575792852}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:16,314]\u001b[0m Trial 23 finished with value: 1.8114251933390288 and parameters: {'lr': 0.05035724806164679, 'hs': 20, 'dropout': 0.13558592800628966}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:21,673]\u001b[0m Trial 24 finished with value: 1.7851181920572123 and parameters: {'lr': 0.08773398764689999, 'hs': 23, 'dropout': 0.11266612029278367}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:26,078]\u001b[0m Trial 25 finished with value: 1.7663167191521165 and parameters: {'lr': 0.07207970605766992, 'hs': 28, 'dropout': 0.14522642079805081}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:32,109]\u001b[0m Trial 26 finished with value: 1.8146729877365155 and parameters: {'lr': 0.037542669139191874, 'hs': 27, 'dropout': 0.17942015081498816}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:36,536]\u001b[0m Trial 27 finished with value: 1.866752671233271 and parameters: {'lr': 0.057174516979725656, 'hs': 29, 'dropout': 0.14663190460386472}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:40,981]\u001b[0m Trial 28 finished with value: 2.025133859346098 and parameters: {'lr': 0.027487564370768918, 'hs': 25, 'dropout': 0.17538933093565934}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:45,651]\u001b[0m Trial 29 finished with value: 1.8445666831472254 and parameters: {'lr': 0.09135452800151861, 'hs': 30, 'dropout': 0.12880095498255317}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:49,307]\u001b[0m Trial 30 finished with value: 2.0481499494818967 and parameters: {'lr': 0.043471040357730875, 'hs': 17, 'dropout': 0.17095863937550168}. Best is trial 15 with value: 1.7307043584556705.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:54,048]\u001b[0m Trial 31 finished with value: 1.6847699027063847 and parameters: {'lr': 0.07583462999712498, 'hs': 25, 'dropout': 0.08878102065609111}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 14:59:58,776]\u001b[0m Trial 32 finished with value: 1.781019229817641 and parameters: {'lr': 0.08093804267302368, 'hs': 26, 'dropout': 0.08554865537354109}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:02,973]\u001b[0m Trial 33 finished with value: 1.8235645194113115 and parameters: {'lr': 0.07243953873497425, 'hs': 22, 'dropout': 0.14401568041687937}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:07,156]\u001b[0m Trial 34 finished with value: 1.7983479076710183 and parameters: {'lr': 0.06919349703517168, 'hs': 15, 'dropout': 0.0868619657183169}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:13,021]\u001b[0m Trial 35 finished with value: 1.7845873700679367 and parameters: {'lr': 0.058860576677257984, 'hs': 22, 'dropout': 0.19087724472260506}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:16,855]\u001b[0m Trial 36 finished with value: 1.808035864211707 and parameters: {'lr': 0.08724883235193848, 'hs': 18, 'dropout': 0.12565666047950075}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:21,487]\u001b[0m Trial 37 finished with value: 1.9846711393834227 and parameters: {'lr': 0.020175626422070523, 'hs': 25, 'dropout': 0.07109375238574092}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:25,874]\u001b[0m Trial 38 finished with value: 1.6986238070183468 and parameters: {'lr': 0.07680898176043154, 'hs': 29, 'dropout': 0.11100941474898754}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:30,653]\u001b[0m Trial 39 finished with value: 1.7764361305166598 and parameters: {'lr': 0.06487723310649243, 'hs': 30, 'dropout': 0.10791891962052777}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:34,900]\u001b[0m Trial 40 finished with value: 1.712240404422437 and parameters: {'lr': 0.09968908553210759, 'hs': 21, 'dropout': 0.0909237358783797}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:38,412]\u001b[0m Trial 41 finished with value: 1.8469005084396206 and parameters: {'lr': 0.09983853369024685, 'hs': 21, 'dropout': 0.09414754797166437}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:42,474]\u001b[0m Trial 42 finished with value: 1.8079789763422902 and parameters: {'lr': 0.09354794314918241, 'hs': 18, 'dropout': 0.07841472068851818}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:46,123]\u001b[0m Trial 43 finished with value: 1.8234106101336731 and parameters: {'lr': 0.07771143015481113, 'hs': 24, 'dropout': 0.05970732687767101}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:51,814]\u001b[0m Trial 44 finished with value: 1.688690131269427 and parameters: {'lr': 0.08702781673014624, 'hs': 26, 'dropout': 0.0922841341000546}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:00:56,825]\u001b[0m Trial 45 finished with value: 1.724317458709048 and parameters: {'lr': 0.08881829852794065, 'hs': 26, 'dropout': 0.10555400443238375}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:00,532]\u001b[0m Trial 46 finished with value: 1.8184165917889283 and parameters: {'lr': 0.08635358871013785, 'hs': 27, 'dropout': 0.09250385610820498}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:05,834]\u001b[0m Trial 47 finished with value: 1.7526492816518182 and parameters: {'lr': 0.09756854357012527, 'hs': 28, 'dropout': 0.10593929167733016}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:10,210]\u001b[0m Trial 48 finished with value: 1.725101721642507 and parameters: {'lr': 0.09163480523180721, 'hs': 31, 'dropout': 0.09220436466923822}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:15,027]\u001b[0m Trial 49 finished with value: 1.7225412511877856 and parameters: {'lr': 0.08225807078809304, 'hs': 24, 'dropout': 0.1099511155964101}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:20,547]\u001b[0m Trial 50 finished with value: 1.7751584751203506 and parameters: {'lr': 0.08189286627072587, 'hs': 23, 'dropout': 0.06612054810276763}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:24,415]\u001b[0m Trial 51 finished with value: 1.7491734136491235 and parameters: {'lr': 0.08905693423325782, 'hs': 24, 'dropout': 0.11090290651688257}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:29,432]\u001b[0m Trial 52 finished with value: 1.8322039467245872 and parameters: {'lr': 0.09504640137115208, 'hs': 26, 'dropout': 0.10256108560339373}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:34,356]\u001b[0m Trial 53 finished with value: 1.748498166166381 and parameters: {'lr': 0.07863157316726459, 'hs': 29, 'dropout': 0.07858003887923994}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:38,872]\u001b[0m Trial 54 finished with value: 1.7448496954089563 and parameters: {'lr': 0.08277288171814307, 'hs': 26, 'dropout': 0.1189358763656745}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:43,557]\u001b[0m Trial 55 finished with value: 1.7571120500708537 and parameters: {'lr': 0.08991395571582086, 'hs': 24, 'dropout': 0.09929414112377248}. Best is trial 31 with value: 1.6847699027063847.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:48,768]\u001b[0m Trial 56 finished with value: 1.6552110797998514 and parameters: {'lr': 0.09642210164064326, 'hs': 21, 'dropout': 0.09532145477749895}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:53,032]\u001b[0m Trial 57 finished with value: 1.8289859371397748 and parameters: {'lr': 0.09769342941674537, 'hs': 20, 'dropout': 0.09569705918680876}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:01:58,144]\u001b[0m Trial 58 finished with value: 1.7865164833879368 and parameters: {'lr': 0.08471230527992377, 'hs': 22, 'dropout': 0.08807869514975383}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:01,636]\u001b[0m Trial 59 finished with value: 1.7447600121178934 and parameters: {'lr': 0.0771863431674579, 'hs': 21, 'dropout': 0.08189294105383814}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:06,551]\u001b[0m Trial 60 finished with value: 1.718761228331668 and parameters: {'lr': 0.09432811555808275, 'hs': 19, 'dropout': 0.07235076027865597}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:11,818]\u001b[0m Trial 61 finished with value: 1.6875091088618266 and parameters: {'lr': 0.09368371251010851, 'hs': 19, 'dropout': 0.07288859396970168}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:16,485]\u001b[0m Trial 62 finished with value: 1.783445783354119 and parameters: {'lr': 0.0945087759928743, 'hs': 19, 'dropout': 0.05889661995305064}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:21,117]\u001b[0m Trial 63 finished with value: 1.7951960290404843 and parameters: {'lr': 0.09838188751275284, 'hs': 19, 'dropout': 0.0724285407585797}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:24,860]\u001b[0m Trial 64 finished with value: 1.7607566130970647 and parameters: {'lr': 0.09224100348152588, 'hs': 16, 'dropout': 0.07522740220448487}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:29,097]\u001b[0m Trial 65 finished with value: 1.7511477086508958 and parameters: {'lr': 0.09652040565106831, 'hs': 17, 'dropout': 0.06731294496228392}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:33,300]\u001b[0m Trial 66 finished with value: 1.837573225439197 and parameters: {'lr': 0.08480249005364202, 'hs': 13, 'dropout': 0.0894651822492374}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:38,161]\u001b[0m Trial 67 finished with value: 1.7464962125110175 and parameters: {'lr': 0.09374303704894753, 'hs': 21, 'dropout': 0.05043825039639501}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:42,058]\u001b[0m Trial 68 finished with value: 1.723696887755426 and parameters: {'lr': 0.09929666144076918, 'hs': 19, 'dropout': 0.07958966142953329}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:45,377]\u001b[0m Trial 69 finished with value: 2.0665461123485973 and parameters: {'lr': 0.0896105004248704, 'hs': 6, 'dropout': 0.0965634380776757}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:50,170]\u001b[0m Trial 70 finished with value: 1.8378608513945087 and parameters: {'lr': 0.08680171773257414, 'hs': 32, 'dropout': 0.08416672399358001}. Best is trial 56 with value: 1.6552110797998514.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:55,080]\u001b[0m Trial 71 finished with value: 1.5718304774695044 and parameters: {'lr': 0.08016797553034109, 'hs': 22, 'dropout': 0.05835189386739724}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:02:59,947]\u001b[0m Trial 72 finished with value: 1.7661870040718994 and parameters: {'lr': 0.0687961382055973, 'hs': 22, 'dropout': 0.061042231039516594}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:04,387]\u001b[0m Trial 73 finished with value: 1.804149590953869 and parameters: {'lr': 0.075262126805797, 'hs': 21, 'dropout': 0.05664716194258221}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:07,946]\u001b[0m Trial 74 finished with value: 1.8721499258629104 and parameters: {'lr': 0.09538534071410941, 'hs': 20, 'dropout': 0.0648208891875158}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:12,050]\u001b[0m Trial 75 finished with value: 1.7843730837406513 and parameters: {'lr': 0.08048854297556424, 'hs': 18, 'dropout': 0.07478920653512267}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:17,413]\u001b[0m Trial 76 finished with value: 1.9977681894150068 and parameters: {'lr': 0.013970865091851269, 'hs': 23, 'dropout': 0.06916864494092907}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:22,074]\u001b[0m Trial 77 finished with value: 1.784176991158395 and parameters: {'lr': 0.09198512509410271, 'hs': 25, 'dropout': 0.09021632351088253}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:26,235]\u001b[0m Trial 78 finished with value: 1.796565388786014 and parameters: {'lr': 0.08592104028371284, 'hs': 19, 'dropout': 0.056059533515355434}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:30,716]\u001b[0m Trial 79 finished with value: 1.766484271415974 and parameters: {'lr': 0.07410559217059691, 'hs': 28, 'dropout': 0.10287432895711209}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:35,675]\u001b[0m Trial 80 finished with value: 1.6348822025564431 and parameters: {'lr': 0.09035264287520635, 'hs': 29, 'dropout': 0.11553666415292936}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:40,236]\u001b[0m Trial 81 finished with value: 1.7266183448105075 and parameters: {'lr': 0.09994078208092441, 'hs': 29, 'dropout': 0.11611933988384511}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:44,965]\u001b[0m Trial 82 finished with value: 1.6837407764809054 and parameters: {'lr': 0.09041005482860026, 'hs': 27, 'dropout': 0.13388455088400839}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:49,285]\u001b[0m Trial 83 finished with value: 1.9385093327635665 and parameters: {'lr': 0.09050003364035812, 'hs': 30, 'dropout': 0.13809101375808433}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:03:56,056]\u001b[0m Trial 84 finished with value: 1.7849660780035332 and parameters: {'lr': 0.07855026659973473, 'hs': 27, 'dropout': 0.1229234205100926}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:00,295]\u001b[0m Trial 85 finished with value: 1.7651434708615021 and parameters: {'lr': 0.08356876401545346, 'hs': 31, 'dropout': 0.1255306649725411}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:04,357]\u001b[0m Trial 86 finished with value: 1.7264892132419563 and parameters: {'lr': 0.08788680616405854, 'hs': 27, 'dropout': 0.13065675146162845}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:09,497]\u001b[0m Trial 87 finished with value: 1.8895640027336709 and parameters: {'lr': 0.07014140936567706, 'hs': 28, 'dropout': 0.11437719646092918}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:14,039]\u001b[0m Trial 88 finished with value: 1.9473514398246141 and parameters: {'lr': 0.09643310153323685, 'hs': 23, 'dropout': 0.0984898071269089}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:18,996]\u001b[0m Trial 89 finished with value: 1.6634792822625748 and parameters: {'lr': 0.0923536960404683, 'hs': 29, 'dropout': 0.08227551444258936}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:23,237]\u001b[0m Trial 90 finished with value: 1.8222662989018765 and parameters: {'lr': 0.08015971521398704, 'hs': 29, 'dropout': 0.08165957880411658}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:29,057]\u001b[0m Trial 91 finished with value: 1.7659154607821979 and parameters: {'lr': 0.09216327572349353, 'hs': 30, 'dropout': 0.08480418397498235}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:33,226]\u001b[0m Trial 92 finished with value: 1.790416065607025 and parameters: {'lr': 0.08851332549644259, 'hs': 26, 'dropout': 0.09131022966625793}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:36,933]\u001b[0m Trial 93 finished with value: 1.867460980614778 and parameters: {'lr': 0.0842520061432153, 'hs': 29, 'dropout': 0.10720049133831272}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:42,116]\u001b[0m Trial 94 finished with value: 1.791414693777946 and parameters: {'lr': 0.0967402771706857, 'hs': 31, 'dropout': 0.13861200479107777}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:46,424]\u001b[0m Trial 95 finished with value: 1.915763611176881 and parameters: {'lr': 0.0929289370589675, 'hs': 27, 'dropout': 0.09451480999162162}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:50,421]\u001b[0m Trial 96 finished with value: 1.8251884703744128 and parameters: {'lr': 0.0763433011699536, 'hs': 24, 'dropout': 0.10428854222353245}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:54,296]\u001b[0m Trial 97 finished with value: 1.9533236156023754 and parameters: {'lr': 0.09076539022190992, 'hs': 25, 'dropout': 0.12903806952787614}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:04:58,710]\u001b[0m Trial 98 finished with value: 1.8096425887939322 and parameters: {'lr': 0.06669622726486024, 'hs': 28, 'dropout': 0.10039727230373098}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "\u001b[32m[I 2025-11-01 15:05:03,736]\u001b[0m Trial 99 finished with value: 1.8185126035725527 and parameters: {'lr': 0.0809539770196535, 'hs': 22, 'dropout': 0.11968953500998897}. Best is trial 71 with value: 1.5718304774695044.\u001b[0m\n",
      "('GRU', 2.061948936850146e+17, 190310862.43881872, 1.6587052534397637, 0.6029875248319598, 0.5825042464063288, 'FF', True, 'mse')\n",
      "('GRU', 2.8781554611330246e+17, 203488870.43162772, 1.280408728473629, 0.4645264155612735, 0.665919480601786, 'FF', True, 'mse')\n",
      "('GRU', 4.072312054663393e+17, 230762156.26258448, 1.5941214895732945, 0.5305812103217642, 0.5056062765625764, 'FF', True, 'mse')\n",
      "('GRU', 2.8344393457441392e+17, 203091080.41900504, 2.468709626964935, 0.4346154419986561, 0.6714889977616229, 'FF', True, 'mse')\n",
      "('GRU', 2.455303491360716e+17, 169198930.97167143, 2.331493943871527, 0.4225212956702232, 0.5986613746528016, 'FF', True, 'mse')\n",
      "[!] Adding Laplacian positional encoding.\n",
      "Time LapPE: 4.662512302398682\n",
      "[!] Adding WL positional encoding.\n",
      "Time WL PE: 1.0529794692993164\n",
      "Epoch 182:  18%|| 182/1000 [00:59<04:50,  2.81it/s, lr=0.000313, time=0.4, trai"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:40:33,173]\u001b[0m Trial 48 finished with value: 0.021328714886820126 and parameters: {'lr': 0.008268285387427469, 'hs': 21, 'dropout': 0.06489939096012384}. Best is trial 41 with value: 0.020010322959780336.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:40:39,956]\u001b[0m Trial 49 finished with value: 0.023300488343669434 and parameters: {'lr': 0.00975474474528676, 'hs': 16, 'dropout': 0.1328667629007407}. Best is trial 41 with value: 0.020010322959780336.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.0927421406613508e+18, 883126739.1740448, -0.4580117463560405, 'ARIMA', True, 'beta')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.0662118152988095e+18, 885107015.5406271, -0.4337960859656267, 'ARIMA', True, 'beta')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.1776624472289759e+18, 920578107.7380737, -0.4895234856619981, 'ARIMA', True, 'beta')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.1069019087305504e+18, 864184206.5800437, -0.33581331386467617, 'ARIMA', True, 'beta')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 8.39699806192201e+17, 842120831.8057023, -1.2924682657002373, 'ARIMA', True, 'beta')\n",
      "\u001b[32m[I 2025-10-30 06:45:59,506]\u001b[0m A new study created in memory with name: no-name-25bcc161-45bb-4b11-a83f-d1a2d30a4b29\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:46:07,042]\u001b[0m Trial 0 finished with value: 0.00235465897897037 and parameters: {'lr': 0.007536580977427676, 'hs': 29, 'dropout': 0.12994729704541064}. Best is trial 0 with value: 0.00235465897897037.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:46:21,900]\u001b[0m Trial 1 finished with value: 0.0037050262609168824 and parameters: {'lr': 0.0012413191133765675, 'hs': 30, 'dropout': 0.1448928741057417}. Best is trial 0 with value: 0.00235465897897037.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:46:33,415]\u001b[0m Trial 2 finished with value: 0.0034286828645880944 and parameters: {'lr': 0.004163862591815302, 'hs': 9, 'dropout': 0.13300965914925694}. Best is trial 0 with value: 0.00235465897897037.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:46:43,009]\u001b[0m Trial 3 finished with value: 0.0022945395151650985 and parameters: {'lr': 0.005158914223915607, 'hs': 22, 'dropout': 0.06963816052774775}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:46:51,626]\u001b[0m Trial 4 finished with value: 0.0028996731355311503 and parameters: {'lr': 0.009798753804702218, 'hs': 11, 'dropout': 0.07991116477996292}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:47:02,239]\u001b[0m Trial 5 finished with value: 0.003555293130166185 and parameters: {'lr': 0.005999617357360666, 'hs': 4, 'dropout': 0.06026690848718266}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:47:13,748]\u001b[0m Trial 6 finished with value: 0.0030895946793250257 and parameters: {'lr': 0.003648716659283844, 'hs': 12, 'dropout': 0.10475337779081771}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:47:23,592]\u001b[0m Trial 7 finished with value: 0.002467835586890921 and parameters: {'lr': 0.005023493935671683, 'hs': 16, 'dropout': 0.0874397190344825}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:47:32,770]\u001b[0m Trial 8 finished with value: 0.003446738215887767 and parameters: {'lr': 0.009135221220665766, 'hs': 9, 'dropout': 0.16587560209252866}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:47:48,471]\u001b[0m Trial 9 finished with value: 0.0031217801730974077 and parameters: {'lr': 0.0015500035249650858, 'hs': 26, 'dropout': 0.084965982545608}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:47:55,210]\u001b[0m Trial 10 finished with value: 0.002613503609926978 and parameters: {'lr': 0.007094090211905547, 'hs': 22, 'dropout': 0.1855346174842241}. Best is trial 3 with value: 0.0022945395151650985.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:00,615]\u001b[0m Trial 11 finished with value: 0.002250085794637469 and parameters: {'lr': 0.007652171255965646, 'hs': 32, 'dropout': 0.1170396292868759}. Best is trial 11 with value: 0.002250085794637469.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:07,911]\u001b[0m Trial 12 finished with value: 0.002191200730187747 and parameters: {'lr': 0.007658273751800081, 'hs': 23, 'dropout': 0.050516240249409955}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:16,816]\u001b[0m Trial 13 finished with value: 0.002343969709945978 and parameters: {'lr': 0.008111877882893038, 'hs': 23, 'dropout': 0.051751142939108534}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:25,839]\u001b[0m Trial 14 finished with value: 0.002314099623201893 and parameters: {'lr': 0.006951845258638331, 'hs': 32, 'dropout': 0.10379098327996372}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:34,260]\u001b[0m Trial 15 finished with value: 0.002733991912038897 and parameters: {'lr': 0.00896746931979562, 'hs': 17, 'dropout': 0.10777068458093647}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:41,570]\u001b[0m Trial 16 finished with value: 0.002525863076972354 and parameters: {'lr': 0.0060804456134143136, 'hs': 27, 'dropout': 0.1555014696685152}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:52,607]\u001b[0m Trial 17 finished with value: 0.0031750793109985454 and parameters: {'lr': 0.0028803008189848397, 'hs': 24, 'dropout': 0.17365200415501264}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:48:59,491]\u001b[0m Trial 18 finished with value: 0.0026924671899461947 and parameters: {'lr': 0.008410598271307551, 'hs': 19, 'dropout': 0.19290807850581404}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:49:39,347]\u001b[0m Trial 19 finished with value: 0.01526645627525966 and parameters: {'lr': 9.206780485355136e-05, 'hs': 32, 'dropout': 0.11653196845569651}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:49:46,994]\u001b[0m Trial 20 finished with value: 0.0025183720365582925 and parameters: {'lr': 0.009902928148737718, 'hs': 19, 'dropout': 0.14156567195106431}. Best is trial 12 with value: 0.002191200730187747.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:49:56,085]\u001b[0m Trial 21 finished with value: 0.002183974295126214 and parameters: {'lr': 0.0058440943592461695, 'hs': 26, 'dropout': 0.06705726317415453}. Best is trial 21 with value: 0.002183974295126214.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:05,334]\u001b[0m Trial 22 finished with value: 0.002212963162778842 and parameters: {'lr': 0.006062121286814598, 'hs': 27, 'dropout': 0.06879368166561822}. Best is trial 21 with value: 0.002183974295126214.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:11,463]\u001b[0m Trial 23 finished with value: 0.0021919473411977472 and parameters: {'lr': 0.006301616786833091, 'hs': 26, 'dropout': 0.06655598041729667}. Best is trial 21 with value: 0.002183974295126214.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:21,077]\u001b[0m Trial 24 finished with value: 0.002128556279837506 and parameters: {'lr': 0.006496165860130108, 'hs': 25, 'dropout': 0.050285006173618314}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:30,972]\u001b[0m Trial 25 finished with value: 0.002348126120887396 and parameters: {'lr': 0.004375259687448014, 'hs': 21, 'dropout': 0.05017459429407485}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:39,900]\u001b[0m Trial 26 finished with value: 0.0024658624151274178 and parameters: {'lr': 0.005328177890917322, 'hs': 25, 'dropout': 0.0909589335990904}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:48,499]\u001b[0m Trial 27 finished with value: 0.0023935727176527507 and parameters: {'lr': 0.0067888679743189915, 'hs': 29, 'dropout': 0.059261361275246636}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:50:56,789]\u001b[0m Trial 28 finished with value: 0.002393999189180559 and parameters: {'lr': 0.00800793282691575, 'hs': 19, 'dropout': 0.07923325958005795}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:05,768]\u001b[0m Trial 29 finished with value: 0.0022230819615842623 and parameters: {'lr': 0.007404121973750125, 'hs': 29, 'dropout': 0.07381552801441622}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:16,649]\u001b[0m Trial 30 finished with value: 0.0030061809910398606 and parameters: {'lr': 0.0027830682478292754, 'hs': 15, 'dropout': 0.09427476566076651}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:25,691]\u001b[0m Trial 31 finished with value: 0.0023329827584210425 and parameters: {'lr': 0.006434294721416983, 'hs': 25, 'dropout': 0.06174939765747482}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:35,094]\u001b[0m Trial 32 finished with value: 0.0022151891327599517 and parameters: {'lr': 0.005873481263424454, 'hs': 28, 'dropout': 0.05046302844806919}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:43,099]\u001b[0m Trial 33 finished with value: 0.0024576848460857 and parameters: {'lr': 0.004203991149431666, 'hs': 24, 'dropout': 0.06389527677848868}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:51,839]\u001b[0m Trial 34 finished with value: 0.002398345289220548 and parameters: {'lr': 0.005421139799213294, 'hs': 21, 'dropout': 0.07300514655284375}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:51:59,601]\u001b[0m Trial 35 finished with value: 0.002248257228425783 and parameters: {'lr': 0.006571917482511979, 'hs': 26, 'dropout': 0.057737692009864686}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:07,962]\u001b[0m Trial 36 finished with value: 0.0022581244218617337 and parameters: {'lr': 0.004668397014014714, 'hs': 20, 'dropout': 0.07890112451627561}. Best is trial 24 with value: 0.002128556279837506.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:16,396]\u001b[0m Trial 37 finished with value: 0.002104776521535009 and parameters: {'lr': 0.008786167388712728, 'hs': 30, 'dropout': 0.06690505254916872}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:24,287]\u001b[0m Trial 38 finished with value: 0.0031469232273247487 and parameters: {'lr': 0.008894613726822117, 'hs': 4, 'dropout': 0.09590003714557825}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:32,829]\u001b[0m Trial 39 finished with value: 0.0021611150417767595 and parameters: {'lr': 0.008613874742267328, 'hs': 30, 'dropout': 0.05771806372304085}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:40,749]\u001b[0m Trial 40 finished with value: 0.0022265167837430956 and parameters: {'lr': 0.009486882847758999, 'hs': 30, 'dropout': 0.07411649501594371}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:50,031]\u001b[0m Trial 41 finished with value: 0.0021694111130156654 and parameters: {'lr': 0.00855452503324251, 'hs': 30, 'dropout': 0.05648131366997193}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:52:58,576]\u001b[0m Trial 42 finished with value: 0.0022072333316871147 and parameters: {'lr': 0.008500630391464476, 'hs': 30, 'dropout': 0.05669964171733944}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:06,726]\u001b[0m Trial 43 finished with value: 0.002406143964532289 and parameters: {'lr': 0.009255558017419936, 'hs': 30, 'dropout': 0.0674491375801014}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:14,474]\u001b[0m Trial 44 finished with value: 0.009656367603658704 and parameters: {'lr': 0.008574538765234868, 'hs': 2, 'dropout': 0.08150111918566302}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:21,579]\u001b[0m Trial 45 finished with value: 0.002333596630823207 and parameters: {'lr': 0.007389364542578484, 'hs': 31, 'dropout': 0.05939968659468844}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:28,194]\u001b[0m Trial 46 finished with value: 0.0023942042520601696 and parameters: {'lr': 0.007896766399416161, 'hs': 28, 'dropout': 0.07127378006534549}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:39,627]\u001b[0m Trial 47 finished with value: 0.0025254444977458935 and parameters: {'lr': 0.003605929644419375, 'hs': 28, 'dropout': 0.08665186700197754}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:47,399]\u001b[0m Trial 48 finished with value: 0.002268328919277352 and parameters: {'lr': 0.009370638778533625, 'hs': 31, 'dropout': 0.056254135289796545}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "\u001b[32m[I 2025-10-30 06:53:55,097]\u001b[0m Trial 49 finished with value: 0.0022264169683208546 and parameters: {'lr': 0.00997771390154512, 'hs': 31, 'dropout': 0.06376077970199892}. Best is trial 37 with value: 0.002104776521535009.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.7009880978826768e+17, 160554549.5048026, 0.7864915674771878, 'ARIMA', True, 'bce')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.4280981057223627e+17, 163217873.84986198, 0.8226182515571584, 'ARIMA', True, 'bce')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 9.2244588249776e+16, 135439789.07065275, 0.8088188559292857, 'ARIMA', True, 'bce')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 6.454218328443199e+16, 130359780.88279203, 0.8438834336939052, 'ARIMA', True, 'bce')\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1127: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.lstm(\n",
      "('LSTM', 1.777379012703171e+17, 169022123.03643182, 0.7307776966661192, 'ARIMA', True, 'bce')\n",
      "\u001b[32m[I 2025-10-30 06:56:18,611]\u001b[0m A new study created in memory with name: no-name-24119d69-cdca-425a-9b12-dee3c09bc6c2\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:56:29,954]\u001b[0m Trial 0 finished with value: 0.02556765002560717 and parameters: {'lr': 0.003940241646682268, 'hs': 10, 'dropout': 0.11597374819937235}. Best is trial 0 with value: 0.02556765002560717.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:56:38,326]\u001b[0m Trial 1 finished with value: 0.023879473715407922 and parameters: {'lr': 0.008436947807244815, 'hs': 9, 'dropout': 0.17086761381191337}. Best is trial 1 with value: 0.023879473715407922.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:56:48,998]\u001b[0m Trial 2 finished with value: 0.024970798111783866 and parameters: {'lr': 0.001953209685759818, 'hs': 18, 'dropout': 0.19782526388498345}. Best is trial 1 with value: 0.023879473715407922.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:56:59,454]\u001b[0m Trial 3 finished with value: 0.023815077665751524 and parameters: {'lr': 0.008789558185709628, 'hs': 20, 'dropout': 0.08595390359554886}. Best is trial 3 with value: 0.023815077665751524.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:57:25,710]\u001b[0m Trial 4 finished with value: 0.03314149049263374 and parameters: {'lr': 0.0013501853088902732, 'hs': 3, 'dropout': 0.11715142581304074}. Best is trial 3 with value: 0.023815077665751524.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:57:32,897]\u001b[0m Trial 5 finished with value: 0.02485875378406942 and parameters: {'lr': 0.008515075787380354, 'hs': 19, 'dropout': 0.10619196154397939}. Best is trial 3 with value: 0.023815077665751524.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:57:40,814]\u001b[0m Trial 6 finished with value: 0.02224486364538847 and parameters: {'lr': 0.006043172326956716, 'hs': 16, 'dropout': 0.12525356888878603}. Best is trial 6 with value: 0.02224486364538847.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:57:49,889]\u001b[0m Trial 7 finished with value: 0.02535442161610596 and parameters: {'lr': 0.005661009669362265, 'hs': 12, 'dropout': 0.12883799849424554}. Best is trial 6 with value: 0.02224486364538847.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:57:58,950]\u001b[0m Trial 8 finished with value: 0.026783116001767766 and parameters: {'lr': 0.008904045201036869, 'hs': 10, 'dropout': 0.16609487212856505}. Best is trial 6 with value: 0.02224486364538847.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:58:07,007]\u001b[0m Trial 9 finished with value: 0.022081630162957725 and parameters: {'lr': 0.004220243049174236, 'hs': 24, 'dropout': 0.1401558290294213}. Best is trial 9 with value: 0.022081630162957725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:58:15,795]\u001b[0m Trial 10 finished with value: 0.01969486003686791 and parameters: {'lr': 0.0036034732410865794, 'hs': 30, 'dropout': 0.06667770623617954}. Best is trial 10 with value: 0.01969486003686791.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:58:25,483]\u001b[0m Trial 11 finished with value: 0.020872679690659274 and parameters: {'lr': 0.003971563338117171, 'hs': 30, 'dropout': 0.07146607167600838}. Best is trial 10 with value: 0.01969486003686791.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:58:35,701]\u001b[0m Trial 12 finished with value: 0.021885857431733075 and parameters: {'lr': 0.0026994954114202764, 'hs': 30, 'dropout': 0.05058509702604504}. Best is trial 10 with value: 0.01969486003686791.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n",
      "\u001b[32m[I 2025-10-30 06:58:55,142]\u001b[0m Trial 13 finished with value: 0.02350631826730473 and parameters: {'lr': 0.0005770668042771234, 'hs': 32, 'dropout': 0.054944922968261756}. Best is trial 10 with value: 0.01969486003686791.\u001b[0m\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:1394: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1479.)\n",
      "  result = _VF.gru(\n"
     ]
    }
   ],
   "source": [
    "!python experiments.py --imputation FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26317921",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install torchdata==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install torchvision==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd258879",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install torchtext==0.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc103f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ced98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install torch==2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9856a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b91876",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install -U dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5a8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install pytorch_forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ece39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install timekan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.10 install torchvision==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea73a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
