{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41ddf7d-4569-4104-a2b1-3ac816fb97ac",
   "metadata": {},
   "source": [
    "# Load trade and production data (1993-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87871bd-9e8a-49b1-ab71-af7ec2cc12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "trade_directory = \"trade_data\"\n",
    "\n",
    "trades = []\n",
    "for file in os.listdir(trade_directory):\n",
    "    if file.endswith(\".csv\"): \n",
    "        trades.append(pd.read_csv(os.path.join(trade_directory, file),sep=\",\",index_col=False,encoding = 'ISO-8859-1'))\n",
    "\n",
    "\n",
    "trade = pd.concat(trades,ignore_index=True, axis=0)\n",
    "trade = trade[[\"refYear\",\"reporterDesc\",\"partnerDesc\",\"flowDesc\",\"qty\",\"isAggregate\"]].fillna(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42c56e-6eef-4d80-abd4-f71a4ec1a89e",
   "metadata": {},
   "source": [
    "# fill gaps with with different imputation strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00291378-0263-4553-aa1a-00be081d9ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def need2be_imputed(tmp,target=\"qty\"):\n",
    "    zero_stat = []\n",
    "    if len(tmp) > 0:\n",
    "        right_empty = 0\n",
    "        zeros = 0\n",
    "        flag = True\n",
    "        for i,row in tmp.reindex().sort_index(ascending=False).iterrows():\n",
    "            if  math.isnan(row[target]):\n",
    "                zeros += 1\n",
    "                zero_stat.append(1)\n",
    "                if flag:\n",
    "                    right_empty += 1    \n",
    "            else:\n",
    "                flag = False\n",
    "                zero_stat.append(0)\n",
    "        if right_empty < 3 and zeros > 0:\n",
    "            return True, 0, zero_stat\n",
    "        else:    \n",
    "            if zeros > 0 and right_empty == zeros:\n",
    "                return False, right_empty, zero_stat\n",
    "            else:\n",
    "                if zeros == 0:\n",
    "                    return False, 0, zero_stat\n",
    "                else:    \n",
    "                    return True, right_empty, zero_stat\n",
    "    else:    \n",
    "        return False, 0, zero_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b7e09-bb4c-49b1-a148-94e0f82c71c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original trade size: 104142\n",
      "Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 211/211 [2:37:38<00:00, 44.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trade size after de-duplication: 104142\n",
      "Impute nans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████▏    | 183/211 [7:03:29<2:05:21, 268.64s/it]"
     ]
    }
   ],
   "source": [
    "from sktime.transformations.series.impute import Imputer\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "np.seterr(divide = 'ignore') \n",
    "\n",
    "reporters = np.unique(trade['reporterDesc'])\n",
    "\n",
    "print(\"Original trade size:\", len(trade))\n",
    "\n",
    "# drop duplicate lines\n",
    "print(\"Drop duplicates\")\n",
    "for r in tqdm(reporters):\n",
    "    for partner in np.unique(trade[trade['reporterDesc'] == r][\"partnerDesc\"].to_numpy()):\n",
    "        for flow in [\"Import\",\"Export\"]:\n",
    "            years = np.unique(trade[\"refYear\"].to_numpy())\n",
    "            for year in years:\n",
    "                year_trade = trade[(trade['reporterDesc']==r)&(trade['flowDesc']==flow)&(trade['refYear']==year)&(trade['partnerDesc']==partner)]\n",
    "                if len(year_trade) > 1:\n",
    "                    remain = year_trade['qty'].idxmax()\n",
    "                    #print(r,partner,len(year_trade))\n",
    "                    for id_,_ in year_trade.iterrows():\n",
    "                        if id_ != remain:\n",
    "                            trade = trade.drop(id_)\n",
    "                   #print(\"Control:\",r,partner, len(trade[(trade['reporterDesc']==r)&(trade['flowDesc']==flow)&(trade['refYear']==year)&(trade['partnerDesc']==partner)]))        \n",
    "print(\"Trade size after de-duplication:\",len(trade))\n",
    "\n",
    "print(\"Impute nans\")\n",
    "\n",
    "trade_copy = copy.deepcopy(trade)\n",
    "\n",
    "imputers = {\"ARIMA\":Imputer(method=\"forecaster\", forecaster=AutoARIMA(suppress_warnings=True)), \"FF\":Imputer(method=\"ffill\"),\"INTERPOLATION\":Imputer(method=\"linear\"),\"NO_IMP\":None}\n",
    "\n",
    "zero_cnts_years = {\"Import\":[],\"Export\":[]}\n",
    "\n",
    "years = np.sort(np.unique(trade[\"refYear\"].to_numpy())) # do not impute last 5 years\n",
    "\n",
    "for imp_type in imputers:\n",
    "    trade = trade_copy\n",
    "\n",
    "    for r in tqdm(reporters):\n",
    "        for partner in np.unique(trade[trade['reporterDesc'] == r][\"partnerDesc\"].to_numpy()):\n",
    "            for flow in [\"Import\",\"Export\"]:\n",
    "                for year in years:\n",
    "                    if len(trade[(trade['reporterDesc']==r)&(trade['flowDesc']==flow)&(trade['refYear']==year)&(trade['partnerDesc']==partner)]) == 0:\n",
    "                         row =  pd.DataFrame({\"refYear\":year,\t\"reporterDesc\":r,\t\"partnerDesc\":partner,\t\"flowDesc\":flow,\"qty\":math.nan,\t\"isAggregate\":False},index=[0])\n",
    "                         trade = pd.concat([trade.loc[:],row],axis=0).reset_index(drop=True)\n",
    "    \n",
    "                tmp = trade[(trade['reporterDesc']==r)&(trade['flowDesc']==flow)&(trade['partnerDesc']==partner)]\n",
    "                flag,zero_len, zero_cnts = need2be_imputed(tmp)\n",
    "                zero_cnts_years[flow].append(zero_cnts)\n",
    "                if flag:\n",
    "                    X = tmp.sort_values(by='refYear')\n",
    "                    #TODO - set index\n",
    "                    transformer = imputers[imp_type]\n",
    "                    if transformer is not None:\n",
    "                        X_ = transformer.fit_transform(X['qty'].to_numpy().flatten()[:len(X) - zero_len])\n",
    "                        #print(X['qty'].to_numpy().flatten(), \"-->\", X_.flatten())\n",
    "                        for i,v in enumerate(X.iterrows()):\n",
    "                            idx, row = v\n",
    "                            if i < len(X_) and row['refYear'] < years[-5]: # do not impute last 5 years\n",
    "                                if X_[i] > 0.:\n",
    "                                    trade.loc[idx,\"qty\"] = X_[i]\n",
    "                                    #print(idx,row,\"->\",X_[i])\n",
    "                            \n",
    "    \n",
    "    trade = trade.fillna(0.) # fill the remaining Nans with 0\n",
    "    \n",
    "    print(\"Final trade size:\",len(trade))\n",
    "    \n",
    "    trade.to_csv(\"trade\" + imp_type + \".csv\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1775e5e7-aa9e-432f-95ba-0043a7b62d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd>DataFrame(zero_cnts_years).to_csv(\"import_export_zero_stat.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6c137-5887-44f9-8a9d-90a980186c6e",
   "metadata": {},
   "source": [
    "# Prepare FAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c3ec8de-3548-4b44-aba0-ecd91a41e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium-Luxembourg --> Belgium-Luxembourg (...1998)\n",
      "Bosnia and Herzegovina --> Bosnia Herzegovina\n",
      "China, mainland --> China\n",
      "Democratic Republic of the Congo --> Dem. Rep. of the Congo\n",
      "Iran (Islamic Republic of) --> Iran\n",
      "Netherlands (Kingdom of the) --> Netherlands\n",
      "Republic of Korea --> Rep. of Korea\n",
      "Republic of Moldova --> Rep. of Moldova\n",
      "Serbia and Montenegro --> Serbia and Montenegro (...2005)\n",
      "Palestine --> State of Palestine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/pmdarima/compat/sklearn.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2677 Area     State of Palestine\n",
      "Year                   1993\n",
      "Value                   NaN\n",
      "Name: 2677, dtype: object -> [32483.45721171]\n",
      "2678 Area     State of Palestine\n",
      "Year                   1994\n",
      "Value               18241.0\n",
      "Name: 2678, dtype: object -> [18241.]\n",
      "2679 Area     State of Palestine\n",
      "Year                   1995\n",
      "Value               40732.0\n",
      "Name: 2679, dtype: object -> [40732.]\n",
      "2680 Area     State of Palestine\n",
      "Year                   1996\n",
      "Value               30872.0\n",
      "Name: 2680, dtype: object -> [30872.]\n",
      "2681 Area     State of Palestine\n",
      "Year                   1997\n",
      "Value               28310.0\n",
      "Name: 2681, dtype: object -> [28310.]\n",
      "2682 Area     State of Palestine\n",
      "Year                   1998\n",
      "Value               36523.0\n",
      "Name: 2682, dtype: object -> [36523.]\n",
      "2683 Area     State of Palestine\n",
      "Year                   1999\n",
      "Value               11052.0\n",
      "Name: 2683, dtype: object -> [11052.]\n",
      "2684 Area     State of Palestine\n",
      "Year                   2000\n",
      "Value               53422.0\n",
      "Name: 2684, dtype: object -> [53422.]\n",
      "2685 Area     State of Palestine\n",
      "Year                   2001\n",
      "Value               24983.0\n",
      "Name: 2685, dtype: object -> [24983.]\n",
      "2686 Area     State of Palestine\n",
      "Year                   2002\n",
      "Value               54308.0\n",
      "Name: 2686, dtype: object -> [54308.]\n",
      "2687 Area     State of Palestine\n",
      "Year                   2003\n",
      "Value               44947.0\n",
      "Name: 2687, dtype: object -> [44947.]\n",
      "2688 Area     State of Palestine\n",
      "Year                   2004\n",
      "Value               46340.0\n",
      "Name: 2688, dtype: object -> [46340.]\n",
      "2689 Area     State of Palestine\n",
      "Year                   2005\n",
      "Value               44720.0\n",
      "Name: 2689, dtype: object -> [44720.]\n",
      "2690 Area     State of Palestine\n",
      "Year                   2006\n",
      "Value               39430.0\n",
      "Name: 2690, dtype: object -> [39430.]\n",
      "2691 Area     State of Palestine\n",
      "Year                   2007\n",
      "Value               39799.0\n",
      "Name: 2691, dtype: object -> [39799.]\n",
      "2692 Area     State of Palestine\n",
      "Year                   2008\n",
      "Value               31826.0\n",
      "Name: 2692, dtype: object -> [31826.]\n",
      "2693 Area     State of Palestine\n",
      "Year                   2009\n",
      "Value               30000.0\n",
      "Name: 2693, dtype: object -> [30000.]\n",
      "2694 Area     State of Palestine\n",
      "Year                   2010\n",
      "Value               17380.0\n",
      "Name: 2694, dtype: object -> [17380.]\n",
      "2695 Area     State of Palestine\n",
      "Year                   2011\n",
      "Value               17840.0\n",
      "Name: 2695, dtype: object -> [17840.]\n",
      "2696 Area     State of Palestine\n",
      "Year                   2012\n",
      "Value               26670.0\n",
      "Name: 2696, dtype: object -> [26670.]\n",
      "2697 Area     State of Palestine\n",
      "Year                   2013\n",
      "Value               41720.0\n",
      "Name: 2697, dtype: object -> [41720.]\n",
      "2698 Area     State of Palestine\n",
      "Year                   2014\n",
      "Value               41720.0\n",
      "Name: 2698, dtype: object -> [41720.]\n",
      "2699 Area     State of Palestine\n",
      "Year                   2015\n",
      "Value               26320.0\n",
      "Name: 2699, dtype: object -> [26320.]\n",
      "2700 Area     State of Palestine\n",
      "Year                   2016\n",
      "Value               37030.0\n",
      "Name: 2700, dtype: object -> [37030.]\n",
      "2701 Area     State of Palestine\n",
      "Year                   2017\n",
      "Value              34559.88\n",
      "Name: 2701, dtype: object -> [34559.88]\n",
      "2702 Area     State of Palestine\n",
      "Year                   2018\n",
      "Value               69080.0\n",
      "Name: 2702, dtype: object -> [69080.]\n",
      "South Sudan --> Sudan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/keen/.pyenv/versions/3.9.13/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6336 Area     Sudan\n",
      "Year      1993\n",
      "Value      NaN\n",
      "Name: 6336, dtype: object -> [299940.91290093]\n",
      "6337 Area     Sudan\n",
      "Year      1994\n",
      "Value      NaN\n",
      "Name: 6337, dtype: object -> [322987.79141663]\n",
      "6338 Area     Sudan\n",
      "Year      1995\n",
      "Value      NaN\n",
      "Name: 6338, dtype: object -> [322987.79141663]\n",
      "6339 Area     Sudan\n",
      "Year      1996\n",
      "Value      NaN\n",
      "Name: 6339, dtype: object -> [322987.79141663]\n",
      "6340 Area     Sudan\n",
      "Year      1997\n",
      "Value      NaN\n",
      "Name: 6340, dtype: object -> [322987.79141663]\n",
      "6341 Area     Sudan\n",
      "Year      1998\n",
      "Value      NaN\n",
      "Name: 6341, dtype: object -> [322987.79141663]\n",
      "6342 Area     Sudan\n",
      "Year      1999\n",
      "Value      NaN\n",
      "Name: 6342, dtype: object -> [322987.79141663]\n",
      "6343 Area     Sudan\n",
      "Year      2000\n",
      "Value      NaN\n",
      "Name: 6343, dtype: object -> [322987.79141663]\n",
      "6344 Area     Sudan\n",
      "Year      2001\n",
      "Value      NaN\n",
      "Name: 6344, dtype: object -> [322987.79141663]\n",
      "6345 Area     Sudan\n",
      "Year      2002\n",
      "Value      NaN\n",
      "Name: 6345, dtype: object -> [322987.79141663]\n",
      "6346 Area     Sudan\n",
      "Year      2003\n",
      "Value      NaN\n",
      "Name: 6346, dtype: object -> [322987.79141663]\n",
      "6347 Area     Sudan\n",
      "Year      2004\n",
      "Value      NaN\n",
      "Name: 6347, dtype: object -> [322987.79141663]\n",
      "6348 Area     Sudan\n",
      "Year      2005\n",
      "Value      NaN\n",
      "Name: 6348, dtype: object -> [322987.79141663]\n",
      "6349 Area     Sudan\n",
      "Year      2006\n",
      "Value      NaN\n",
      "Name: 6349, dtype: object -> [322987.79141663]\n",
      "6350 Area     Sudan\n",
      "Year      2007\n",
      "Value      NaN\n",
      "Name: 6350, dtype: object -> [322987.79141663]\n",
      "6351 Area     Sudan\n",
      "Year      2008\n",
      "Value      NaN\n",
      "Name: 6351, dtype: object -> [322987.79141663]\n",
      "6352 Area     Sudan\n",
      "Year      2009\n",
      "Value      NaN\n",
      "Name: 6352, dtype: object -> [322987.79141663]\n",
      "6353 Area     Sudan\n",
      "Year      2010\n",
      "Value      NaN\n",
      "Name: 6353, dtype: object -> [322987.79141663]\n",
      "6354 Area     Sudan\n",
      "Year      2011\n",
      "Value      NaN\n",
      "Name: 6354, dtype: object -> [322987.79141663]\n",
      "3204 Area     Sudan\n",
      "Year      2012\n",
      "Value      NaN\n",
      "Name: 3204, dtype: object -> [322987.79141663]\n",
      "3247 Area        Sudan\n",
      "Year         2012\n",
      "Value    324000.0\n",
      "Name: 3247, dtype: object -> [324000.]\n",
      "3248 Area        Sudan\n",
      "Year         2013\n",
      "Value    265000.0\n",
      "Name: 3248, dtype: object -> [265000.]\n",
      "3205 Area     Sudan\n",
      "Year      2013\n",
      "Value      NaN\n",
      "Name: 3205, dtype: object -> [266470.02634819]\n",
      "3206 Area     Sudan\n",
      "Year      2014\n",
      "Value      NaN\n",
      "Name: 3206, dtype: object -> [266470.02634819]\n",
      "Sudan (former) --> Sudan (...2011)\n",
      "Syrian Arab Republic --> Syria\n",
      "United States of America --> USA\n",
      "United Kingdom of Great Britain and Northern Ireland --> United Kingdom\n",
      "United Republic of Tanzania --> United Rep. of Tanzania\n",
      "Venezuela (Bolivarian Republic of) --> Venezuela\n",
      "Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▉                                 | 45/211 [00:00<00:03, 46.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████▊     | 184/211 [00:03<00:00, 48.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:04<00:00, 49.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium-Luxembourg --> Belgium-Luxembourg (...1998)\n",
      "Bosnia and Herzegovina --> Bosnia Herzegovina\n",
      "China, mainland --> China\n",
      "Democratic Republic of the Congo --> Dem. Rep. of the Congo\n",
      "Iran (Islamic Republic of) --> Iran\n",
      "Netherlands (Kingdom of the) --> Netherlands\n",
      "Republic of Korea --> Rep. of Korea\n",
      "Republic of Moldova --> Rep. of Moldova\n",
      "Serbia and Montenegro --> Serbia and Montenegro (...2005)\n",
      "Palestine --> State of Palestine\n",
      "2677 Area     State of Palestine\n",
      "Year                   1993\n",
      "Value                   NaN\n",
      "Name: 2677, dtype: object -> [18241.]\n",
      "2678 Area     State of Palestine\n",
      "Year                   1994\n",
      "Value               18241.0\n",
      "Name: 2678, dtype: object -> [18241.]\n",
      "2679 Area     State of Palestine\n",
      "Year                   1995\n",
      "Value               40732.0\n",
      "Name: 2679, dtype: object -> [40732.]\n",
      "2680 Area     State of Palestine\n",
      "Year                   1996\n",
      "Value               30872.0\n",
      "Name: 2680, dtype: object -> [30872.]\n",
      "2681 Area     State of Palestine\n",
      "Year                   1997\n",
      "Value               28310.0\n",
      "Name: 2681, dtype: object -> [28310.]\n",
      "2682 Area     State of Palestine\n",
      "Year                   1998\n",
      "Value               36523.0\n",
      "Name: 2682, dtype: object -> [36523.]\n",
      "2683 Area     State of Palestine\n",
      "Year                   1999\n",
      "Value               11052.0\n",
      "Name: 2683, dtype: object -> [11052.]\n",
      "2684 Area     State of Palestine\n",
      "Year                   2000\n",
      "Value               53422.0\n",
      "Name: 2684, dtype: object -> [53422.]\n",
      "2685 Area     State of Palestine\n",
      "Year                   2001\n",
      "Value               24983.0\n",
      "Name: 2685, dtype: object -> [24983.]\n",
      "2686 Area     State of Palestine\n",
      "Year                   2002\n",
      "Value               54308.0\n",
      "Name: 2686, dtype: object -> [54308.]\n",
      "2687 Area     State of Palestine\n",
      "Year                   2003\n",
      "Value               44947.0\n",
      "Name: 2687, dtype: object -> [44947.]\n",
      "2688 Area     State of Palestine\n",
      "Year                   2004\n",
      "Value               46340.0\n",
      "Name: 2688, dtype: object -> [46340.]\n",
      "2689 Area     State of Palestine\n",
      "Year                   2005\n",
      "Value               44720.0\n",
      "Name: 2689, dtype: object -> [44720.]\n",
      "2690 Area     State of Palestine\n",
      "Year                   2006\n",
      "Value               39430.0\n",
      "Name: 2690, dtype: object -> [39430.]\n",
      "2691 Area     State of Palestine\n",
      "Year                   2007\n",
      "Value               39799.0\n",
      "Name: 2691, dtype: object -> [39799.]\n",
      "2692 Area     State of Palestine\n",
      "Year                   2008\n",
      "Value               31826.0\n",
      "Name: 2692, dtype: object -> [31826.]\n",
      "2693 Area     State of Palestine\n",
      "Year                   2009\n",
      "Value               30000.0\n",
      "Name: 2693, dtype: object -> [30000.]\n",
      "2694 Area     State of Palestine\n",
      "Year                   2010\n",
      "Value               17380.0\n",
      "Name: 2694, dtype: object -> [17380.]\n",
      "2695 Area     State of Palestine\n",
      "Year                   2011\n",
      "Value               17840.0\n",
      "Name: 2695, dtype: object -> [17840.]\n",
      "2696 Area     State of Palestine\n",
      "Year                   2012\n",
      "Value               26670.0\n",
      "Name: 2696, dtype: object -> [26670.]\n",
      "2697 Area     State of Palestine\n",
      "Year                   2013\n",
      "Value               41720.0\n",
      "Name: 2697, dtype: object -> [41720.]\n",
      "2698 Area     State of Palestine\n",
      "Year                   2014\n",
      "Value               41720.0\n",
      "Name: 2698, dtype: object -> [41720.]\n",
      "2699 Area     State of Palestine\n",
      "Year                   2015\n",
      "Value               26320.0\n",
      "Name: 2699, dtype: object -> [26320.]\n",
      "2700 Area     State of Palestine\n",
      "Year                   2016\n",
      "Value               37030.0\n",
      "Name: 2700, dtype: object -> [37030.]\n",
      "2701 Area     State of Palestine\n",
      "Year                   2017\n",
      "Value              34559.88\n",
      "Name: 2701, dtype: object -> [34559.88]\n",
      "2702 Area     State of Palestine\n",
      "Year                   2018\n",
      "Value               69080.0\n",
      "Name: 2702, dtype: object -> [69080.]\n",
      "South Sudan --> Sudan\n",
      "6336 Area     Sudan\n",
      "Year      1993\n",
      "Value      NaN\n",
      "Name: 6336, dtype: object -> [324000.]\n",
      "6337 Area     Sudan\n",
      "Year      1994\n",
      "Value      NaN\n",
      "Name: 6337, dtype: object -> [324000.]\n",
      "6338 Area     Sudan\n",
      "Year      1995\n",
      "Value      NaN\n",
      "Name: 6338, dtype: object -> [324000.]\n",
      "6339 Area     Sudan\n",
      "Year      1996\n",
      "Value      NaN\n",
      "Name: 6339, dtype: object -> [324000.]\n",
      "6340 Area     Sudan\n",
      "Year      1997\n",
      "Value      NaN\n",
      "Name: 6340, dtype: object -> [324000.]\n",
      "6341 Area     Sudan\n",
      "Year      1998\n",
      "Value      NaN\n",
      "Name: 6341, dtype: object -> [324000.]\n",
      "6342 Area     Sudan\n",
      "Year      1999\n",
      "Value      NaN\n",
      "Name: 6342, dtype: object -> [324000.]\n",
      "6343 Area     Sudan\n",
      "Year      2000\n",
      "Value      NaN\n",
      "Name: 6343, dtype: object -> [324000.]\n",
      "6344 Area     Sudan\n",
      "Year      2001\n",
      "Value      NaN\n",
      "Name: 6344, dtype: object -> [324000.]\n",
      "6345 Area     Sudan\n",
      "Year      2002\n",
      "Value      NaN\n",
      "Name: 6345, dtype: object -> [324000.]\n",
      "6346 Area     Sudan\n",
      "Year      2003\n",
      "Value      NaN\n",
      "Name: 6346, dtype: object -> [324000.]\n",
      "6347 Area     Sudan\n",
      "Year      2004\n",
      "Value      NaN\n",
      "Name: 6347, dtype: object -> [324000.]\n",
      "6348 Area     Sudan\n",
      "Year      2005\n",
      "Value      NaN\n",
      "Name: 6348, dtype: object -> [324000.]\n",
      "6349 Area     Sudan\n",
      "Year      2006\n",
      "Value      NaN\n",
      "Name: 6349, dtype: object -> [324000.]\n",
      "6350 Area     Sudan\n",
      "Year      2007\n",
      "Value      NaN\n",
      "Name: 6350, dtype: object -> [324000.]\n",
      "6351 Area     Sudan\n",
      "Year      2008\n",
      "Value      NaN\n",
      "Name: 6351, dtype: object -> [324000.]\n",
      "6352 Area     Sudan\n",
      "Year      2009\n",
      "Value      NaN\n",
      "Name: 6352, dtype: object -> [324000.]\n",
      "6353 Area     Sudan\n",
      "Year      2010\n",
      "Value      NaN\n",
      "Name: 6353, dtype: object -> [324000.]\n",
      "6354 Area     Sudan\n",
      "Year      2011\n",
      "Value      NaN\n",
      "Name: 6354, dtype: object -> [324000.]\n",
      "3204 Area     Sudan\n",
      "Year      2012\n",
      "Value      NaN\n",
      "Name: 3204, dtype: object -> [324000.]\n",
      "3247 Area        Sudan\n",
      "Year         2012\n",
      "Value    324000.0\n",
      "Name: 3247, dtype: object -> [324000.]\n",
      "3248 Area        Sudan\n",
      "Year         2013\n",
      "Value    265000.0\n",
      "Name: 3248, dtype: object -> [265000.]\n",
      "3205 Area     Sudan\n",
      "Year      2013\n",
      "Value      NaN\n",
      "Name: 3205, dtype: object -> [265000.]\n",
      "3206 Area     Sudan\n",
      "Year      2014\n",
      "Value      NaN\n",
      "Name: 3206, dtype: object -> [265000.]\n",
      "Sudan (former) --> Sudan (...2011)\n",
      "Syrian Arab Republic --> Syria\n",
      "United States of America --> USA\n",
      "United Kingdom of Great Britain and Northern Ireland --> United Kingdom\n",
      "United Republic of Tanzania --> United Rep. of Tanzania\n",
      "Venezuela (Bolivarian Republic of) --> Venezuela\n",
      "Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▉                                 | 45/211 [00:00<00:03, 46.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████▋    | 189/211 [00:03<00:00, 49.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:04<00:00, 48.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium-Luxembourg --> Belgium-Luxembourg (...1998)\n",
      "Bosnia and Herzegovina --> Bosnia Herzegovina\n",
      "China, mainland --> China\n",
      "Democratic Republic of the Congo --> Dem. Rep. of the Congo\n",
      "Iran (Islamic Republic of) --> Iran\n",
      "Netherlands (Kingdom of the) --> Netherlands\n",
      "Republic of Korea --> Rep. of Korea\n",
      "Republic of Moldova --> Rep. of Moldova\n",
      "Serbia and Montenegro --> Serbia and Montenegro (...2005)\n",
      "Palestine --> State of Palestine\n",
      "2677 Area     State of Palestine\n",
      "Year                   1993\n",
      "Value                   NaN\n",
      "Name: 2677, dtype: object -> [18241.]\n",
      "2678 Area     State of Palestine\n",
      "Year                   1994\n",
      "Value               18241.0\n",
      "Name: 2678, dtype: object -> [18241.]\n",
      "2679 Area     State of Palestine\n",
      "Year                   1995\n",
      "Value               40732.0\n",
      "Name: 2679, dtype: object -> [40732.]\n",
      "2680 Area     State of Palestine\n",
      "Year                   1996\n",
      "Value               30872.0\n",
      "Name: 2680, dtype: object -> [30872.]\n",
      "2681 Area     State of Palestine\n",
      "Year                   1997\n",
      "Value               28310.0\n",
      "Name: 2681, dtype: object -> [28310.]\n",
      "2682 Area     State of Palestine\n",
      "Year                   1998\n",
      "Value               36523.0\n",
      "Name: 2682, dtype: object -> [36523.]\n",
      "2683 Area     State of Palestine\n",
      "Year                   1999\n",
      "Value               11052.0\n",
      "Name: 2683, dtype: object -> [11052.]\n",
      "2684 Area     State of Palestine\n",
      "Year                   2000\n",
      "Value               53422.0\n",
      "Name: 2684, dtype: object -> [53422.]\n",
      "2685 Area     State of Palestine\n",
      "Year                   2001\n",
      "Value               24983.0\n",
      "Name: 2685, dtype: object -> [24983.]\n",
      "2686 Area     State of Palestine\n",
      "Year                   2002\n",
      "Value               54308.0\n",
      "Name: 2686, dtype: object -> [54308.]\n",
      "2687 Area     State of Palestine\n",
      "Year                   2003\n",
      "Value               44947.0\n",
      "Name: 2687, dtype: object -> [44947.]\n",
      "2688 Area     State of Palestine\n",
      "Year                   2004\n",
      "Value               46340.0\n",
      "Name: 2688, dtype: object -> [46340.]\n",
      "2689 Area     State of Palestine\n",
      "Year                   2005\n",
      "Value               44720.0\n",
      "Name: 2689, dtype: object -> [44720.]\n",
      "2690 Area     State of Palestine\n",
      "Year                   2006\n",
      "Value               39430.0\n",
      "Name: 2690, dtype: object -> [39430.]\n",
      "2691 Area     State of Palestine\n",
      "Year                   2007\n",
      "Value               39799.0\n",
      "Name: 2691, dtype: object -> [39799.]\n",
      "2692 Area     State of Palestine\n",
      "Year                   2008\n",
      "Value               31826.0\n",
      "Name: 2692, dtype: object -> [31826.]\n",
      "2693 Area     State of Palestine\n",
      "Year                   2009\n",
      "Value               30000.0\n",
      "Name: 2693, dtype: object -> [30000.]\n",
      "2694 Area     State of Palestine\n",
      "Year                   2010\n",
      "Value               17380.0\n",
      "Name: 2694, dtype: object -> [17380.]\n",
      "2695 Area     State of Palestine\n",
      "Year                   2011\n",
      "Value               17840.0\n",
      "Name: 2695, dtype: object -> [17840.]\n",
      "2696 Area     State of Palestine\n",
      "Year                   2012\n",
      "Value               26670.0\n",
      "Name: 2696, dtype: object -> [26670.]\n",
      "2697 Area     State of Palestine\n",
      "Year                   2013\n",
      "Value               41720.0\n",
      "Name: 2697, dtype: object -> [41720.]\n",
      "2698 Area     State of Palestine\n",
      "Year                   2014\n",
      "Value               41720.0\n",
      "Name: 2698, dtype: object -> [41720.]\n",
      "2699 Area     State of Palestine\n",
      "Year                   2015\n",
      "Value               26320.0\n",
      "Name: 2699, dtype: object -> [26320.]\n",
      "2700 Area     State of Palestine\n",
      "Year                   2016\n",
      "Value               37030.0\n",
      "Name: 2700, dtype: object -> [37030.]\n",
      "2701 Area     State of Palestine\n",
      "Year                   2017\n",
      "Value              34559.88\n",
      "Name: 2701, dtype: object -> [34559.88]\n",
      "2702 Area     State of Palestine\n",
      "Year                   2018\n",
      "Value               69080.0\n",
      "Name: 2702, dtype: object -> [69080.]\n",
      "South Sudan --> Sudan\n",
      "6336 Area     Sudan\n",
      "Year      1993\n",
      "Value      NaN\n",
      "Name: 6336, dtype: object -> [324000.]\n",
      "6337 Area     Sudan\n",
      "Year      1994\n",
      "Value      NaN\n",
      "Name: 6337, dtype: object -> [324000.]\n",
      "6338 Area     Sudan\n",
      "Year      1995\n",
      "Value      NaN\n",
      "Name: 6338, dtype: object -> [324000.]\n",
      "6339 Area     Sudan\n",
      "Year      1996\n",
      "Value      NaN\n",
      "Name: 6339, dtype: object -> [324000.]\n",
      "6340 Area     Sudan\n",
      "Year      1997\n",
      "Value      NaN\n",
      "Name: 6340, dtype: object -> [324000.]\n",
      "6341 Area     Sudan\n",
      "Year      1998\n",
      "Value      NaN\n",
      "Name: 6341, dtype: object -> [324000.]\n",
      "6342 Area     Sudan\n",
      "Year      1999\n",
      "Value      NaN\n",
      "Name: 6342, dtype: object -> [324000.]\n",
      "6343 Area     Sudan\n",
      "Year      2000\n",
      "Value      NaN\n",
      "Name: 6343, dtype: object -> [324000.]\n",
      "6344 Area     Sudan\n",
      "Year      2001\n",
      "Value      NaN\n",
      "Name: 6344, dtype: object -> [324000.]\n",
      "6345 Area     Sudan\n",
      "Year      2002\n",
      "Value      NaN\n",
      "Name: 6345, dtype: object -> [324000.]\n",
      "6346 Area     Sudan\n",
      "Year      2003\n",
      "Value      NaN\n",
      "Name: 6346, dtype: object -> [324000.]\n",
      "6347 Area     Sudan\n",
      "Year      2004\n",
      "Value      NaN\n",
      "Name: 6347, dtype: object -> [324000.]\n",
      "6348 Area     Sudan\n",
      "Year      2005\n",
      "Value      NaN\n",
      "Name: 6348, dtype: object -> [324000.]\n",
      "6349 Area     Sudan\n",
      "Year      2006\n",
      "Value      NaN\n",
      "Name: 6349, dtype: object -> [324000.]\n",
      "6350 Area     Sudan\n",
      "Year      2007\n",
      "Value      NaN\n",
      "Name: 6350, dtype: object -> [324000.]\n",
      "6351 Area     Sudan\n",
      "Year      2008\n",
      "Value      NaN\n",
      "Name: 6351, dtype: object -> [324000.]\n",
      "6352 Area     Sudan\n",
      "Year      2009\n",
      "Value      NaN\n",
      "Name: 6352, dtype: object -> [324000.]\n",
      "6353 Area     Sudan\n",
      "Year      2010\n",
      "Value      NaN\n",
      "Name: 6353, dtype: object -> [324000.]\n",
      "6354 Area     Sudan\n",
      "Year      2011\n",
      "Value      NaN\n",
      "Name: 6354, dtype: object -> [324000.]\n",
      "3204 Area     Sudan\n",
      "Year      2012\n",
      "Value      NaN\n",
      "Name: 3204, dtype: object -> [324000.]\n",
      "3247 Area        Sudan\n",
      "Year         2012\n",
      "Value    324000.0\n",
      "Name: 3247, dtype: object -> [324000.]\n",
      "3248 Area        Sudan\n",
      "Year         2013\n",
      "Value    265000.0\n",
      "Name: 3248, dtype: object -> [265000.]\n",
      "3205 Area     Sudan\n",
      "Year      2013\n",
      "Value      NaN\n",
      "Name: 3205, dtype: object -> [265000.]\n",
      "3206 Area     Sudan\n",
      "Year      2014\n",
      "Value      NaN\n",
      "Name: 3206, dtype: object -> [265000.]\n",
      "Sudan (former) --> Sudan (...2011)\n",
      "Syrian Arab Republic --> Syria\n",
      "United States of America --> USA\n",
      "United Kingdom of Great Britain and Northern Ireland --> United Kingdom\n",
      "United Republic of Tanzania --> United Rep. of Tanzania\n",
      "Venezuela (Bolivarian Republic of) --> Venezuela\n",
      "Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▉                                 | 45/211 [00:00<00:03, 45.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████████████████████████████████▏    | 186/211 [00:03<00:00, 47.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:04<00:00, 48.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belgium-Luxembourg --> Belgium-Luxembourg (...1998)\n",
      "Bosnia and Herzegovina --> Bosnia Herzegovina\n",
      "China, mainland --> China\n",
      "Democratic Republic of the Congo --> Dem. Rep. of the Congo\n",
      "Iran (Islamic Republic of) --> Iran\n",
      "Netherlands (Kingdom of the) --> Netherlands\n",
      "Republic of Korea --> Rep. of Korea\n",
      "Republic of Moldova --> Rep. of Moldova\n",
      "Serbia and Montenegro --> Serbia and Montenegro (...2005)\n",
      "Palestine --> State of Palestine\n",
      "South Sudan --> Sudan\n",
      "Sudan (former) --> Sudan (...2011)\n",
      "Syrian Arab Republic --> Syria\n",
      "United States of America --> USA\n",
      "United Kingdom of Great Britain and Northern Ireland --> United Kingdom\n",
      "United Republic of Tanzania --> United Rep. of Tanzania\n",
      "Venezuela (Bolivarian Republic of) --> Venezuela\n",
      "Drop duplicates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████▉                                 | 45/211 [00:00<00:03, 44.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n",
      "China 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████▌    | 188/211 [00:03<00:00, 48.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n",
      "Sudan 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [00:04<00:00, 48.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "trade = pd.read_csv(\"tradeARIMA.csv\",sep=\";\",index_col=0)\n",
    "reporters = np.unique(trade['reporterDesc'])\n",
    "\n",
    "area_map = {\"Belgium-Luxembourg\":\"Belgium-Luxembourg (...1998)\",\n",
    "\"Bosnia and Herzegovina\":\"Bosnia Herzegovina\",\n",
    "\"China, Taiwan Province of\":\"Taiwan\",\n",
    "\"China, mainland\":\"China\",\n",
    "\"Democratic People's Republic of Korea\":\"Democratic People's Republic of Korea\",\n",
    "\"Democratic Republic of the Congo\":\"Dem. Rep. of the Congo\",\n",
    "\"Iran (Islamic Republic of)\":\"Iran\",\n",
    "\"Netherlands (Kingdom of the)\":\"Netherlands\",\n",
    "\"Palestine\":\"State of Palestine\",\n",
    "\"Republic of Korea\":\"Rep. of Korea\",\n",
    "\"Republic of Moldova\":\"Rep. of Moldova\",\n",
    "\"Serbia and Montenegro\":\"Serbia and Montenegro (...2005)\",\n",
    "\"Somalia\":\"Somalia\",\n",
    "\"South Sudan\":\"Sudan\",\n",
    "\"Sudan (former)\":\"Sudan (...2011)\",\n",
    "\"Syrian Arab Republic\":\"Syria\",\n",
    "\"United Kingdom of Great Britain and Northern Ireland\":\"United Kingdom\",\n",
    "\"United Republic of Tanzania\":\"United Rep. of Tanzania\",\n",
    "\"United States of America\":\"USA\",\n",
    "\"Venezuela (Bolivarian Republic of)\":\"Venezuela\"}\n",
    "\n",
    "area_map_inv = {v:k for k,v in area_map.items()}\n",
    "\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "fao = pd.read_csv(\"prod_data/FAOSTAT_data_en_1-28-2025.csv\")[[\"Area\", \"Year\", \"Value\"]]\n",
    "\n",
    "years = np.unique(trade[\"refYear\"].to_numpy())\n",
    "areas = np.unique(trade['reporterDesc'].to_numpy())\n",
    "\n",
    "zero_cnts_years = {\"Production\":[]}\n",
    "\n",
    "fao_copy = copy.deepcopy(fao)\n",
    "\n",
    "imputers = {\"ARIMA\":Imputer(method=\"forecaster\", forecaster=AutoARIMA(suppress_warnings=True)), \"FF\":Imputer(method=\"ffill\"),\"INTERPOLATION\":Imputer(method=\"linear\"),\"NO_IMP\":None}\n",
    "\n",
    "for imp_type in imputers:\n",
    "    fao = fao_copy\n",
    "\n",
    "    for r in areas:\n",
    "        if r in area_map_inv:\n",
    "            print(area_map_inv[r],\"-->\",r)\n",
    "            for idx,row in fao[fao[\"Area\"] == area_map_inv[r]].iterrows():\n",
    "                row[\"Area\"] = r\n",
    "                fao.loc[idx] = row\n",
    "        \n",
    "    \n",
    "        for year in years:\n",
    "            if len(fao[(fao['Area']==r)&(fao['Year']==year)]) == 0:\n",
    "                 row =  pd.DataFrame({\"Area\":r,\t\"Year\":year,\"Value\":math.nan},index=[0])\n",
    "                 fao = pd.concat([fao.loc[:],row],axis=0).reset_index(drop=True)\n",
    "                \n",
    "    \n",
    "        #if empty:        \n",
    "        #    print(\"Zeros: \", r)\n",
    "        tmp = fao[(fao['Area']==r)]\n",
    "        flag,zero_len,zero_cnts = need2be_imputed(tmp,\"Value\")\n",
    "        zero_cnts_years[\"Production\"].append(zero_cnts)\n",
    "        \n",
    "        if flag:\n",
    "            X = tmp.sort_values(by='Year')\n",
    "            transformer = imputers[imp_type]\n",
    "            if transformer is not None:\n",
    "                X_ = transformer.fit_transform(X['Value'].to_numpy().flatten()[:len(X) - zero_len])\n",
    "        \n",
    "                #print(X['Value'].to_numpy().flatten(), \"-->\", X_.flatten())\n",
    "                for i,v in enumerate(X.iterrows()):\n",
    "                    idx, row = v\n",
    "                    if i < len(X_) and row['Year'] < years[-5]: # do not impute last 5 years\n",
    "                        if X_[i] > 0.:\n",
    "                            fao.loc[idx,\"Value\"] = X_[i]  \n",
    "                            print(idx,row,'->',X_[i])\n",
    "    \n",
    "    print(\"Drop duplicates\")\n",
    "    for r in tqdm(areas):\n",
    "        for year in years:\n",
    "            year_trade = fao[(fao['Area']==r)&(fao['Year']==year)]\n",
    "            if len(year_trade) > 1:\n",
    "                remain = year_trade['Value'].idxmax()\n",
    "                print(r,len(year_trade))\n",
    "                for id_,_ in year_trade.iterrows():\n",
    "                    if id_ != remain:\n",
    "                        fao = fao.drop(id_)\n",
    "                        \n",
    "    fao = fao.fillna(0.)\n",
    "    fao.to_csv(\"fao\" + imp_type + \".csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f03403e-3225-4e75-9167-95ccfc8aaef9",
   "metadata": {},
   "source": [
    "## Calc norm constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bedce36c-6d01-4806-95c1-151f84fbfcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 211/211 [25:15<00:00,  7.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "for imp_type in [\"ARIMA\"]:#, \"FF\",\"INTERPOLATION\",\"NO_IMP\"]:\n",
    "    trade = pd.read_csv(\"trade\" + imp_type + \".csv\",sep=\";\")\n",
    "    fao = pd.read_csv(\"fao\" + imp_type + \".csv\",sep=\";\")\n",
    "    reporters = np.unique(trade['reporterDesc'])\n",
    "\n",
    "    datas = []\n",
    "    part_offset = []\n",
    "    for r in tqdm(reporters):\n",
    "        for partner in np.unique(trade[trade['reporterDesc'] == r][\"partnerDesc\"].to_numpy()):\n",
    "            if r.find(\", nes\")==-1 and r.find(\"North America\")==-1 and r.find(\"World\") == -1 and  r.find(\"Union\") == -1 and r.find(\"19\") == -1 and r.find(\"20\") == -1:\n",
    "                if partner.find(\", nes\")==-1 and partner.find(\"North America\")==-1 and partner.find(\"World\") == -1 and  partner.find(\"Union\") == -1 and partner.find(\"19\") == -1 and partner.find(\"20\") == -1:             \n",
    "                    #print(r,partner)\n",
    "                    data = np.nan_to_num(trade[(trade['reporterDesc'] == r)&(trade['partnerDesc'] == partner)&(trade['flowDesc'] == \"Export\")].sort_values(by='refYear')['qty'].to_numpy().reshape(1,-1,1))\n",
    "                    data2 = np.nan_to_num(trade[(trade['reporterDesc'] == r)&(trade['partnerDesc'] == partner)&(trade['flowDesc'] == \"Import\")].sort_values(by='refYear')['qty'].to_numpy().reshape(1,-1,1))\n",
    "                    data3 = np.nan_to_num(fao[fao[\"Area\"] == r].sort_values(by='Year')[[\"Value\"]].to_numpy().reshape(1,-1,1))\n",
    "                    data4 = np.nan_to_num(fao[fao[\"Area\"] == partner].sort_values(by='Year')[[\"Value\"]].to_numpy().reshape(1,-1,1))\n",
    "                    if data4.shape[1] > 0 and data3.shape[1] > 0:\n",
    "                        #print(data.shape,data2.shape,data3.shape,data4.shape)\n",
    "                        data = np.concatenate([data,data2,data3,data4],axis=2)\n",
    "                        datas.append(data)\n",
    "                        part_offset.append((r,partner,len(datas) - 0))\n",
    "    \n",
    "    base_dataset = np.vstack(datas)\n",
    "    \n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "    np.seterr(divide = 'ignore')\n",
    "    \n",
    "    base_datasetX = base_dataset[:,:30,:]\n",
    "    base_datasety = base_dataset[:,1:31,0]\n",
    "    \n",
    "    #remove lines with many zeros\n",
    "    remain_idxs = (np.abs(base_datasety) < 500000).sum(axis=1) < 2\n",
    "    \n",
    "    base_datasetX = base_datasetX[remain_idxs].reshape(-1,5,4)\n",
    "    base_datasety = base_datasety[remain_idxs]\n",
    "    \n",
    "    #normalize\n",
    "    nz_idxs_y = (base_datasety.reshape(-1,5).sum(axis=1) > 0).flatten()\n",
    "    nz_idx_x = (base_datasetX.sum(axis=1) > 0).prod(axis=1).astype(bool)\n",
    "    res_idx = nz_idxs_y * nz_idx_x\n",
    "    \n",
    "    features_min = base_datasetX[res_idx].reshape(-1,base_datasetX.shape[2]).min(axis=0)\n",
    "    features_max = base_datasetX[res_idx].reshape(-1,base_datasetX.shape[2]).max(axis=0)\n",
    "    \n",
    "    np.save(\"norm_constants\" + imp_type + \".npy\",np.asarray([features_min, features_max]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d48487-34e5-4339-961a-1fa4c2e7c510",
   "metadata": {},
   "source": [
    "# Build graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d80fd0-b483-424b-bb03-c2c917a0b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build a trade map for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb5711-823b-4a96-b07d-ede66963e908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import copy\n",
    "from sktime.transformations.series.impute import Imputer\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "import pickle\n",
    "\n",
    "def all_not_empty(cluster_year):\n",
    "    for j,k in cluster_year[1]:\n",
    "        a = cluster_year[1][j,k][0]\n",
    "        #b = cluster_year[1][j,k][1]\n",
    "        if len(a[a == 0]) > 0:\n",
    "            return False\n",
    "    return True        \n",
    "\n",
    "top10 = np.asarray([\"Russian Federation\", \"Australia\", \"USA\", \"Canada\", \"Ukraine\", \"France\", \"Argentina\", \"Germany\", \"Romania\", \"India\"])\n",
    "imputers = {\"ARIMA\":Imputer(method=\"forecaster\", forecaster=AutoARIMA(suppress_warnings=True)), \"FF\":Imputer(method=\"ffill\"),\"INTERPOLATION\":Imputer(method=\"linear\"),\"NO_IMP\":None}\n",
    "\n",
    "for imp_type in [\"ARIMA\", \"FF\",\"INTERPOLATION\",\"NO_IMP\"]:\n",
    "    trade = pd.read_csv(\"trade\" + imp_type + \".csv\",sep=\";\")\n",
    "    trade_aggregate = trade[trade[\"refYear\"] > 2010][[\"reporterDesc\",\"partnerDesc\",\"qty\"]].groupby([\"reporterDesc\",\"partnerDesc\"]).mean()[\"qty\"]\n",
    "    \n",
    "    trade_map = []\n",
    "    for i,v in trade_aggregate.items():\n",
    "        if i[0].find(\", nes\")==-1 and i[0].find(\"North America\")==-1 and i[0].find(\"World\") == -1 and  i[0].find(\"Union\") == -1 and i[0].find(\"19\") == -1 and i[0].find(\"20\") == -1:\n",
    "            if i[1].find(\", nes\")==-1 and i[1].find(\"North America\")==-1 and i[1].find(\"World\") == -1 and  i[1].find(\"Union\") == -1 and i[1].find(\"19\") == -1 and i[1].find(\"20\") == -1:\n",
    "                trade_map.append([i[0],i[1],v])\n",
    "    \n",
    "    trade_map = np.asarray(trade_map)\n",
    "    \n",
    "    le = OrdinalEncoder(handle_unknown='use_encoded_value',\n",
    "                                     unknown_value=-1)\n",
    "    \n",
    "    le.fit(trade_map[:,:2].reshape(-1,1))\n",
    "    row = le.transform(trade_map[:,0].reshape(-1,1)).astype(int).flatten()\n",
    "    col = le.transform(trade_map[:,1].reshape(-1,1)).astype(int).flatten()\n",
    "    data = trade_map[:,2].astype(float)\n",
    "    num_labels = le.categories_[0].shape[0]\n",
    "    \n",
    "    trade_map_sparse = coo_matrix((data, (row, col)),shape=(num_labels, num_labels)).tolil()\n",
    "    \n",
    "    for i in range(trade_map_sparse.shape[0]):\n",
    "        for j in range(i,trade_map_sparse.shape[1]):\n",
    "            if i == j:\n",
    "                trade_map_sparse[i,j] = 0.\n",
    "            trade_map_sparse[i,j] = (trade_map_sparse[i,j] + trade_map_sparse[j,i]) / 2\n",
    "            if trade_map_sparse[i,j] < 500000.:\n",
    "                trade_map_sparse[i,j] = 0.\n",
    "            trade_map_sparse[j,i] = trade_map_sparse[i,j]\n",
    "            \n",
    "    trade_map_sparse = trade_map_sparse.tocsr()\n",
    "    \n",
    "    trade_export = trade[trade[\"flowDesc\"] == \"Export\"][[\"refYear\",\"reporterDesc\",\"partnerDesc\",\"qty\"]]\n",
    "    trade_export = trade_export.to_numpy()\n",
    "    trade_export = np.hstack([trade_export[:,0].reshape(-1,1),le.transform(trade_export[:,1].reshape(-1,1)).astype(int), le.transform(trade_export[:,2].reshape(-1,1)).astype(int),trade_export[:,3].reshape(-1,1)])    \n",
    "    trade_import = trade[trade[\"flowDesc\"] == \"Import\"][[\"refYear\",\"reporterDesc\",\"partnerDesc\",\"qty\"]]\n",
    "    trade_import = trade_import.to_numpy()\n",
    "    trade_import = np.hstack([trade_import[:,0].reshape(-1,1),le.transform(trade_import[:,1].reshape(-1,1)).astype(int), le.transform(trade_import[:,2].reshape(-1,1)).astype(int),trade_import[:,3].reshape(-1,1)])\n",
    "    preference = - np.ones((num_labels,))\n",
    "    idx = le.transform(top10.reshape(-1,1)).astype(int).flatten()\n",
    "    preference[idx] = 0.\n",
    "\n",
    "    \n",
    "    model = AffinityPropagation(affinity=\"precomputed\",max_iter=10000,preference = None,damping=0.5)\n",
    "    aff_map = trade_map_sparse.toarray()\n",
    "    aff_map = np.nan_to_num(aff_map)\n",
    "    \n",
    "    clustering = model.fit_predict(aff_map)\n",
    "    \n",
    "    ids, counts = np.unique(clustering, return_counts = True)\n",
    "    \n",
    "    avg_weight = trade_map_sparse.mean()\n",
    "    \n",
    "    for i,c in enumerate(ids):\n",
    "        print(c)\n",
    "        G = nx.Graph()\n",
    "    \n",
    "        for j in range(clustering.shape[0]):\n",
    "            if clustering[j] == c:\n",
    "                #print(c,le.inverse_transform([j])[0])\n",
    "                for k in range(clustering.shape[0]):\n",
    "                    if clustering[k] == c:\n",
    "                        if  trade_map_sparse[j,k] > 0.:\n",
    "                            #print(c,le.inverse_transform([j])[0], le.inverse_transform([k])[0], trade_map_sparse[j,k])\n",
    "                            G.add_edge(le.inverse_transform([[j]])[0][0], le.inverse_transform([[k]])[0][0], weight= trade_map_sparse[j,k])\n",
    "                            \n",
    "        elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] > avg_weight*2.5]\n",
    "        ealarge = [(u, v) for (u, v, d) in G.edges(data=True) if ((d[\"weight\"] > avg_weight*1.2) and (d[\"weight\"] <= avg_weight*2.5))]\n",
    "        emed = [(u, v) for (u, v, d) in G.edges(data=True) if ((d[\"weight\"] > avg_weight*0.8) and (d[\"weight\"] <= avg_weight*1.2))]\n",
    "        esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] <= avg_weight*0.8]\n",
    "    \n",
    "        if len(elarge + esmall+emed+ealarge) > 2 and len(elarge) > 0:\n",
    "            layout = nx.spring_layout(G, seed=7,weight=None)\n",
    "            #nx.draw(G, layout)\n",
    "            nx.draw_networkx_nodes(G, layout, node_size=200,alpha=0.4)\n",
    "        \n",
    "            # edges\n",
    "            nx.draw_networkx_edges(G, layout, edgelist=elarge, width=1.5,alpha=0.5,edge_color=\"r\")\n",
    "            nx.draw_networkx_edges(\n",
    "                G, layout, edgelist=ealarge, width=1.0, alpha=0.7, edge_color=\"y\"\n",
    "            )           \n",
    "            nx.draw_networkx_edges(\n",
    "                G, layout, edgelist=emed, width=0.9, alpha=0.7, edge_color=\"g\"\n",
    "            )        \n",
    "            nx.draw_networkx_edges(\n",
    "                G, layout, edgelist=esmall, width=0.5, alpha=0.7, edge_color=\"b\"\n",
    "            )\n",
    "            \n",
    "            # node labels\n",
    "            nx.draw_networkx_labels(G, layout, font_size=8, font_family=\"sans-serif\")\n",
    "            # edge weight labels\n",
    "            #edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "            #nx.draw_networkx_edge_labels(G, layout, edge_labels,font_size=6)\n",
    "            plt.show()   \n",
    "            years = np.unique(trade_export[:,0])\n",
    "\n",
    "    trade_clusters = []\n",
    "    #; un['num_states'] : nb of states, an integer (N)\n",
    "    #; un['production'] : tensor of size N, each element is a production value, a float number > 0\n",
    "    #; un['export'] : tensor of size N x N, each element is a value of export, a float number > 0\n",
    "    #; un['pred_export']\n",
    "    \n",
    "    cluster_year = {}\n",
    "    \n",
    "    for i,c in enumerate(ids):\n",
    "        print(\"Cluster \",c)\n",
    "        for year in range(1993,2023,5):\n",
    "            countries = {}\n",
    "            cdata = {}\n",
    "            for j in range(clustering.shape[0]):\n",
    "                if clustering[j] == c:\n",
    "                    for k in range(clustering.shape[0]):\n",
    "                        if clustering[k] == c:\n",
    "                            ty = trade_export[(trade_export[:,0] >= year)&(trade_export[:,0] < year + 7)&(trade_export[:,1] == j)&(trade_export[:,2] == k)]\n",
    "                            tyi = trade_import[(trade_import[:,0] >= year)&(trade_import[:,0] < year + 7)&(trade_import[:,1] == j)&(trade_import[:,2] == k)]\n",
    "                            if len(ty) > 0:\n",
    "                                countries[j] = True\n",
    "                                countries[k] = True\n",
    "                                datas = np.zeros((5,2))\n",
    "                                targets = np.zeros((5,))\n",
    "                                too_small_flag = 0\n",
    "                                for y in range(year,year + 5):\n",
    "                                    val = ty[ty[:,0] == y]\n",
    "                                    imp_val = tyi[tyi[:,0] == y]\n",
    "                                    if len(val) > 0:\n",
    "                                        if val[0,3] < 500000:\n",
    "                                            too_small_flag += 1    \n",
    "                                        datas[y - year,0] = val[0,3]\n",
    "    \n",
    "                                        if len(imp_val) > 0:\n",
    "                                            datas[y - year,1] = imp_val[0,3]\n",
    "                                        val = ty[ty[:,0] == y + 1]\n",
    "                                        if len(val) > 0:\n",
    "                                            targets[y - year] = val[0,3]# - datas[y - year,0]\n",
    "                                        else:\n",
    "                                            if y > year:\n",
    "                                                print(c,y,j,k,\"got prev target\")\n",
    "                                                targets[y - year] = targets[y - year - 1]\n",
    "                                    else:\n",
    "                                        too_small_flag += 1       \n",
    "                                if (datas[:,0] > 0).sum() > 4 and too_small_flag < 2:\n",
    "                                    cdata[(j,k)] = [datas, targets]  \n",
    "            if len(cdata) > 0:                     \n",
    "                cluster_year[(c,year)] = [countries,cdata]\n",
    "    features_min, features_max = np.load(\"norm_constants\" + imp_type +\".npy\",allow_pickle=True)\n",
    "\n",
    "    for is_normed in [True, False]:\n",
    "        if is_normed:\n",
    "            #norm\n",
    "            for c,y in cluster_year:\n",
    "                for j,k in cluster_year[c,y][1]:\n",
    "                    cluster_year[c,y][1][j,k][1] = cluster_year[c,y][1][j,k][1] / (features_max[0])\n",
    "                    cluster_year[c,y][1][j,k][1][cluster_year[c,y][1][j,k][1] > 1.] = 1.\n",
    "                    cluster_year[c,y][1][j,k][1][cluster_year[c,y][1][j,k][1] < -1.] = -1.        \n",
    "                    cluster_year[c,y][1][j,k][0] = (cluster_year[c,y][1][j,k][0] - features_min[:2]) / (features_max[:2] - features_min[:2])\n",
    "        else:\n",
    "            #rescale it anyway to escape overflaws in exp()\n",
    "            for c,y in cluster_year:\n",
    "                for j,k in cluster_year[c,y][1]:\n",
    "                    cluster_year[c,y][1][j,k][1] = cluster_year[c,y][1][j,k][1] / 100000\n",
    "                    cluster_year[c,y][1][j,k][0] = cluster_year[c,y][1][j,k][0] / 100000\n",
    "        \n",
    "        fao = pd.read_csv(\"fao\" + imp_type + \".csv\",sep=\";\")[[\"Area\", \"Year\", \"Value\"]].to_numpy()\n",
    "        fao = np.hstack([le.transform(fao[:,0].reshape(-1,1)).astype(int),fao[:,1:3]])\n",
    "        #add fao\n",
    "        todel = []\n",
    "        for c,y in cluster_year:\n",
    "            for j,k in cluster_year[c,y][1]:\n",
    "                years = []\n",
    "                years2 = []\n",
    "                for yr in range(y, y + 5):\n",
    "                    fcy = fao[(fao[:,0] == j)&(fao[:,1] == yr)]\n",
    "                    if len(fcy) > 0 and not np.isnan(fcy[0,2]):\n",
    "                        years.append(fcy[0,2])\n",
    "                    else:\n",
    "                        #print(\"zero prod:\",c,y,j,k,yr)\n",
    "                        years.append(0.)\n",
    "        \n",
    "                    fc = fao[(fao[:,0] == k).flatten()]\n",
    "                    if len(fc) > 0:\n",
    "                        fcy = fc[fc[:,1] == yr]\n",
    "                        if len(fcy) > 0 and not np.isnan(fcy[0,2]):\n",
    "                            years2.append(fcy[0,2])\n",
    "                        else:\n",
    "                            years2.append(0.)        \n",
    "                years = np.asarray(years)  \n",
    "                years2 = np.asarray(years2)  \n",
    "                if years.sum() == 0:\n",
    "                    todel.append((c,y,j,k))    \n",
    "                else: \n",
    "                    #years[years == 0.] = years.mean()\n",
    "                    \n",
    "                    transformer = imputers[imp_type]\n",
    "                    if transformer is not None and y < 2019: # do not impute test\n",
    "                        years = transformer.fit_transform(years.reshape(1,-1)).flatten()            \n",
    "                    else:\n",
    "                        years = years.flatten()\n",
    "                    tmp =  copy.deepcopy(cluster_year[c,y][1][j,k][0])\n",
    "                    if is_normed:\n",
    "                        cluster_year[c,y][1][j,k][0] = np.hstack([ tmp, np.asarray(years - features_min[2]).reshape(-1,1) / (features_max[2] - features_min[2]),np.asarray(years2 - features_min[2]).reshape(-1,1) / (features_max[2] - features_min[2])])\n",
    "                    else:\n",
    "                        cluster_year[c,y][1][j,k][0] = np.hstack([ tmp, np.asarray(years).reshape(-1,1),np.asarray(years2).reshape(-1,1)])\n",
    "             \n",
    "        #remove small or empty clusters\n",
    "        for c,y,j,k in todel:\n",
    "            if (c,y) in cluster_year:\n",
    "                del cluster_year[c,y][1][j,k]    \n",
    "                if len(cluster_year[c,y][1]) < 3:\n",
    "                    del cluster_year[c,y]\n",
    "    \n",
    "        cluster_year_train = {}\n",
    "        cluster_year_test = {}\n",
    "        for c,y in cluster_year:\n",
    "            if y > 2018:\n",
    "                if all_not_empty(cluster_year[c,y]): # leave only the clusters that does not need imputation\n",
    "                    cluster_year_test[(c,y)] = cluster_year[c,y]\n",
    "            else:    \n",
    "                cluster_year_train[(c,y)] = cluster_year[c,y]\n",
    "                \n",
    "        with open('cluster_year' + imp_type + str(is_normed) +  '_train.pkl', 'wb') as f:\n",
    "            pickle.dump(cluster_year_train, f)\n",
    "    \n",
    "        with open('cluster_year' + imp_type + str(is_normed) +  '_test.pkl', 'wb') as f:\n",
    "            pickle.dump(cluster_year_test, f)\n",
    "        \n",
    "        with open('name_encoder' + imp_type + '.pkl', 'wb') as f:\n",
    "            pickle.dump(le, f)                             \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9173b3e-e9ac-4558-a81f-4ad1f77f228d",
   "metadata": {},
   "source": [
    "## Draw export distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65369dea-e427-4545-b15b-8e8a4c1caa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targs = []\n",
    "for c, y in cluster_year:\n",
    "    for j,k in cluster_year[c,y][1]:\n",
    "        targs += [cluster_year[c,y][1][j,k][1]]\n",
    "\n",
    "atargs = np.hstack(targs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(atargs.flatten(), bins=50)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
